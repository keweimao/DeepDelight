{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b67b084a",
   "metadata": {},
   "source": [
    "## 1. Data pre-process"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea0bada0",
   "metadata": {},
   "source": [
    "Combine the questions file and source text together"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "546510c8",
   "metadata": {},
   "source": [
    "from langchain.document_loaders import JSONLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import GPT4AllEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.llms import GPT4All\n",
    "from langchain.chains import RetrievalQA\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import json\n",
    "from pathlib import Path\n",
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d16c869",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import JSONLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import GPT4AllEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.llms import GPT4All\n",
    "from langchain.chains import RetrievalQA\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import json\n",
    "from pathlib import Path\n",
    "from langchain.prompts import PromptTemplate\n",
    "import logging\n",
    "import time\n",
    "from langchain.embeddings.huggingface import HuggingFaceInstructEmbeddings\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b0b51d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path='E:/QA/article_segment.json'\n",
    "data = json.loads(Path(file_path).read_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e457c827",
   "metadata": {},
   "outputs": [],
   "source": [
    "text=''\n",
    "for i in data['newsdial-984'][\"seg_dialog\"]:\n",
    "    text+=i['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "85c051ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in data['newsdial-984']['prev_ctx']:\n",
    "    text+=i['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ec5e385e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'And one senator, for example today, Senator Bob Casey, a Democrat from Pennsylvania, sent a letter to the president urging him - I\\'m quoting from the letter - he says, \"to put an end to these practices immediately, to ensure that the investment decisions being made by Freddie Mac are in line with the intent of Congress and the greater needs of our economy.\" So we also spoke today with Senator Johnny Isakson, a Republican from Georgia, who\\'s also interested in reforming Freddie Mac and Fannie Mae. So I think there are people on Capitol Hill who are starting to really ponder, What is the structure of these organizations and what role do they play? What\\'s appropriate for them to do? And this is just sort of an interesting look at conflicts of interest. We are not, in any way - our story has not said that it is illegal, just that it raises questions about how it functions.Well, you did quote Alan Boyce in your story, a former bond trader who\\'s been involved in efforts to push for more refinancing of home loans. Freddie Mac, he said, prevented households from being able to take advantage of today\\'s mortgage rates and then bet on it. You say, well, Freddie Mac has two arms, one, the left hand, did not necessarily know what the right hand is doing. However, they seemed to be miraculously working in concert.And there are people in Congress now who are starting to wonder about whether or not this should be changed, at the moment, as the laws are structured, and as Freddie Mac\\'s mission is, which is to not go broke. You know, it\\'s supposed to be a solvent organization doing its business, but it\\'s also supposed to be helping homeowners. This structure could be called into question.'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9e4d3068",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee71f220",
   "metadata": {},
   "outputs": [],
   "source": [
    "Conv = pd.read_json(\"E:/QA/article_segment.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "df4891b5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>newsdial-984</th>\n",
       "      <th>newsdial-924</th>\n",
       "      <th>newsdial-599</th>\n",
       "      <th>newsdial-184</th>\n",
       "      <th>newsdial-144</th>\n",
       "      <th>newsdial-880</th>\n",
       "      <th>newsdial-983</th>\n",
       "      <th>newsdial-129</th>\n",
       "      <th>newsdial-956</th>\n",
       "      <th>newsdial-987</th>\n",
       "      <th>...</th>\n",
       "      <th>newsdial-4842</th>\n",
       "      <th>newsdial-1384</th>\n",
       "      <th>supreme_court-4434</th>\n",
       "      <th>enron_wisrlab-2432</th>\n",
       "      <th>newsdial-3004</th>\n",
       "      <th>enron_wisrlab-1707</th>\n",
       "      <th>newsdial-3646</th>\n",
       "      <th>supreme_court-1113</th>\n",
       "      <th>newsdial-3104</th>\n",
       "      <th>newsdial-3275</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>prev_ctx</th>\n",
       "      <td>[{'id': 'newsidal-NPR-166-26', 'speaker': 'MAR...</td>\n",
       "      <td>[{'id': 'newsidal-NPR-162-25', 'speaker': 'NEA...</td>\n",
       "      <td>[{'id': 'newsidal-NPR-132-10', 'speaker': 'RAC...</td>\n",
       "      <td>[{'id': 'newsidal-NPR-38-10', 'speaker': 'Ms. ...</td>\n",
       "      <td>[{'id': 'newsidal-NPR-31-12', 'speaker': 'FARA...</td>\n",
       "      <td>[{'id': 'newsidal-NPR-159-100', 'speaker': 'KA...</td>\n",
       "      <td>[{'id': 'newsidal-NPR-166-23', 'speaker': 'NEA...</td>\n",
       "      <td>[{'id': 'newsidal-NPR-28-25', 'speaker': 'Ms. ...</td>\n",
       "      <td>[{'id': 'newsidal-NPR-163-145', 'speaker': 'SO...</td>\n",
       "      <td>[{'id': 'newsidal-NPR-166-35', 'speaker': 'JEF...</td>\n",
       "      <td>...</td>\n",
       "      <td>[{'id': 'newsidal-NPR-692-3', 'speaker': 'ELIZ...</td>\n",
       "      <td>[{'id': 'newsidal-NPR-219-102', 'speaker': 'PE...</td>\n",
       "      <td>[{'id': 'court-04-698-28361', 'speaker': 'JUST...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[{'id': 'newsidal-NPR-486-57', 'speaker': 'NEA...</td>\n",
       "      <td>[{'id': 'enron-enron_wisrlab_60462-0', 'speake...</td>\n",
       "      <td>[{'id': 'newsidal-NPR-554-23', 'speaker': 'I m...</td>\n",
       "      <td>[{'id': 'court-03-636-7031', 'speaker': 'JUSTI...</td>\n",
       "      <td>[{'id': 'newsidal-NPR-491-208', 'speaker': 'ST...</td>\n",
       "      <td>[{'id': 'newsidal-NPR-506-9', 'speaker': 'FARA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>seg_dialog</th>\n",
       "      <td>[{'id': 'newsidal-NPR-166-27', 'speaker': 'MAR...</td>\n",
       "      <td>[{'id': 'newsidal-NPR-162-26', 'speaker': 'AMY...</td>\n",
       "      <td>[{'id': 'newsidal-NPR-132-11', 'speaker': 'URI...</td>\n",
       "      <td>[{'id': 'newsidal-NPR-38-11', 'speaker': 'Ms. ...</td>\n",
       "      <td>[{'id': 'newsidal-NPR-31-13', 'speaker': 'FARA...</td>\n",
       "      <td>[{'id': 'newsidal-NPR-159-101', 'speaker': 'KA...</td>\n",
       "      <td>[{'id': 'newsidal-NPR-166-24', 'speaker': 'CHR...</td>\n",
       "      <td>[{'id': 'newsidal-NPR-28-26', 'speaker': 'MADE...</td>\n",
       "      <td>[{'id': 'newsidal-NPR-163-146', 'speaker': 'NE...</td>\n",
       "      <td>[{'id': 'newsidal-NPR-166-36', 'speaker': 'JEF...</td>\n",
       "      <td>...</td>\n",
       "      <td>[{'id': 'newsidal-NPR-692-4', 'speaker': 'MELI...</td>\n",
       "      <td>[{'id': 'newsidal-NPR-219-103', 'speaker': 'JO...</td>\n",
       "      <td>[{'id': 'court-04-698-28362', 'speaker': 'MR. ...</td>\n",
       "      <td>[{'id': 'enron-enron_wisrlab_13011-0', 'speake...</td>\n",
       "      <td>[{'id': 'newsidal-NPR-486-58', 'speaker': 'RIC...</td>\n",
       "      <td>[{'id': 'enron-enron_wisrlab_60462-1', 'speake...</td>\n",
       "      <td>[{'id': 'newsidal-NPR-554-24', 'speaker': 'I m...</td>\n",
       "      <td>[{'id': 'court-03-636-7032', 'speaker': 'MR. D...</td>\n",
       "      <td>[{'id': 'newsidal-NPR-491-209', 'speaker': 'NE...</td>\n",
       "      <td>[{'id': 'newsidal-NPR-506-10', 'speaker': 'Dr....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_count</th>\n",
       "      <td>237</td>\n",
       "      <td>226</td>\n",
       "      <td>221</td>\n",
       "      <td>248</td>\n",
       "      <td>272</td>\n",
       "      <td>217</td>\n",
       "      <td>213</td>\n",
       "      <td>333</td>\n",
       "      <td>204</td>\n",
       "      <td>263</td>\n",
       "      <td>...</td>\n",
       "      <td>236</td>\n",
       "      <td>228</td>\n",
       "      <td>222</td>\n",
       "      <td>246</td>\n",
       "      <td>240</td>\n",
       "      <td>245</td>\n",
       "      <td>239</td>\n",
       "      <td>284</td>\n",
       "      <td>295</td>\n",
       "      <td>215</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 18728 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 newsdial-984  \\\n",
       "prev_ctx    [{'id': 'newsidal-NPR-166-26', 'speaker': 'MAR...   \n",
       "seg_dialog  [{'id': 'newsidal-NPR-166-27', 'speaker': 'MAR...   \n",
       "word_count                                                237   \n",
       "\n",
       "                                                 newsdial-924  \\\n",
       "prev_ctx    [{'id': 'newsidal-NPR-162-25', 'speaker': 'NEA...   \n",
       "seg_dialog  [{'id': 'newsidal-NPR-162-26', 'speaker': 'AMY...   \n",
       "word_count                                                226   \n",
       "\n",
       "                                                 newsdial-599  \\\n",
       "prev_ctx    [{'id': 'newsidal-NPR-132-10', 'speaker': 'RAC...   \n",
       "seg_dialog  [{'id': 'newsidal-NPR-132-11', 'speaker': 'URI...   \n",
       "word_count                                                221   \n",
       "\n",
       "                                                 newsdial-184  \\\n",
       "prev_ctx    [{'id': 'newsidal-NPR-38-10', 'speaker': 'Ms. ...   \n",
       "seg_dialog  [{'id': 'newsidal-NPR-38-11', 'speaker': 'Ms. ...   \n",
       "word_count                                                248   \n",
       "\n",
       "                                                 newsdial-144  \\\n",
       "prev_ctx    [{'id': 'newsidal-NPR-31-12', 'speaker': 'FARA...   \n",
       "seg_dialog  [{'id': 'newsidal-NPR-31-13', 'speaker': 'FARA...   \n",
       "word_count                                                272   \n",
       "\n",
       "                                                 newsdial-880  \\\n",
       "prev_ctx    [{'id': 'newsidal-NPR-159-100', 'speaker': 'KA...   \n",
       "seg_dialog  [{'id': 'newsidal-NPR-159-101', 'speaker': 'KA...   \n",
       "word_count                                                217   \n",
       "\n",
       "                                                 newsdial-983  \\\n",
       "prev_ctx    [{'id': 'newsidal-NPR-166-23', 'speaker': 'NEA...   \n",
       "seg_dialog  [{'id': 'newsidal-NPR-166-24', 'speaker': 'CHR...   \n",
       "word_count                                                213   \n",
       "\n",
       "                                                 newsdial-129  \\\n",
       "prev_ctx    [{'id': 'newsidal-NPR-28-25', 'speaker': 'Ms. ...   \n",
       "seg_dialog  [{'id': 'newsidal-NPR-28-26', 'speaker': 'MADE...   \n",
       "word_count                                                333   \n",
       "\n",
       "                                                 newsdial-956  \\\n",
       "prev_ctx    [{'id': 'newsidal-NPR-163-145', 'speaker': 'SO...   \n",
       "seg_dialog  [{'id': 'newsidal-NPR-163-146', 'speaker': 'NE...   \n",
       "word_count                                                204   \n",
       "\n",
       "                                                 newsdial-987  ...  \\\n",
       "prev_ctx    [{'id': 'newsidal-NPR-166-35', 'speaker': 'JEF...  ...   \n",
       "seg_dialog  [{'id': 'newsidal-NPR-166-36', 'speaker': 'JEF...  ...   \n",
       "word_count                                                263  ...   \n",
       "\n",
       "                                                newsdial-4842  \\\n",
       "prev_ctx    [{'id': 'newsidal-NPR-692-3', 'speaker': 'ELIZ...   \n",
       "seg_dialog  [{'id': 'newsidal-NPR-692-4', 'speaker': 'MELI...   \n",
       "word_count                                                236   \n",
       "\n",
       "                                                newsdial-1384  \\\n",
       "prev_ctx    [{'id': 'newsidal-NPR-219-102', 'speaker': 'PE...   \n",
       "seg_dialog  [{'id': 'newsidal-NPR-219-103', 'speaker': 'JO...   \n",
       "word_count                                                228   \n",
       "\n",
       "                                           supreme_court-4434  \\\n",
       "prev_ctx    [{'id': 'court-04-698-28361', 'speaker': 'JUST...   \n",
       "seg_dialog  [{'id': 'court-04-698-28362', 'speaker': 'MR. ...   \n",
       "word_count                                                222   \n",
       "\n",
       "                                           enron_wisrlab-2432  \\\n",
       "prev_ctx                                                   []   \n",
       "seg_dialog  [{'id': 'enron-enron_wisrlab_13011-0', 'speake...   \n",
       "word_count                                                246   \n",
       "\n",
       "                                                newsdial-3004  \\\n",
       "prev_ctx    [{'id': 'newsidal-NPR-486-57', 'speaker': 'NEA...   \n",
       "seg_dialog  [{'id': 'newsidal-NPR-486-58', 'speaker': 'RIC...   \n",
       "word_count                                                240   \n",
       "\n",
       "                                           enron_wisrlab-1707  \\\n",
       "prev_ctx    [{'id': 'enron-enron_wisrlab_60462-0', 'speake...   \n",
       "seg_dialog  [{'id': 'enron-enron_wisrlab_60462-1', 'speake...   \n",
       "word_count                                                245   \n",
       "\n",
       "                                                newsdial-3646  \\\n",
       "prev_ctx    [{'id': 'newsidal-NPR-554-23', 'speaker': 'I m...   \n",
       "seg_dialog  [{'id': 'newsidal-NPR-554-24', 'speaker': 'I m...   \n",
       "word_count                                                239   \n",
       "\n",
       "                                           supreme_court-1113  \\\n",
       "prev_ctx    [{'id': 'court-03-636-7031', 'speaker': 'JUSTI...   \n",
       "seg_dialog  [{'id': 'court-03-636-7032', 'speaker': 'MR. D...   \n",
       "word_count                                                284   \n",
       "\n",
       "                                                newsdial-3104  \\\n",
       "prev_ctx    [{'id': 'newsidal-NPR-491-208', 'speaker': 'ST...   \n",
       "seg_dialog  [{'id': 'newsidal-NPR-491-209', 'speaker': 'NE...   \n",
       "word_count                                                295   \n",
       "\n",
       "                                                newsdial-3275  \n",
       "prev_ctx    [{'id': 'newsidal-NPR-506-9', 'speaker': 'FARA...  \n",
       "seg_dialog  [{'id': 'newsidal-NPR-506-10', 'speaker': 'Dr....  \n",
       "word_count                                                215  \n",
       "\n",
       "[3 rows x 18728 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2b3882c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "QA = pd.read_json(\"E:/QAConv-V1.0/QAConv-V1.0/sample.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b532d877",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "QA['text']=''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f5356862",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'openslack-2635'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "QA.iloc[0]['article_segment_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "08554956",
   "metadata": {},
   "outputs": [],
   "source": [
    "QA.loc[0,'text']='dasdawd'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a44c9d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(QA)):\n",
    "    text=''\n",
    "    for j in data[QA.iloc[i]['article_segment_id']]['prev_ctx']:\n",
    "        text+=j['text']\n",
    "    for k in data[QA.iloc[i]['article_segment_id']][\"seg_dialog\"]:\n",
    "        text+=k['text']\n",
    "    QA.loc[i,'text']=text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f16e5558",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'QA' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m QA\u001b[38;5;241m.\u001b[39mto_json(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mQA_data_sample.json\u001b[39m\u001b[38;5;124m'\u001b[39m, orient\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrecords\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'QA' is not defined"
     ]
    }
   ],
   "source": [
    "QA.to_json('QA_data_sample.json', orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "12c6aca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path='E:/QA/QA_data_sample.json'\n",
    "combined_data = json.loads(Path(file_path).read_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c10bcd23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Python']\n",
      "['Mr. Kneedler']\n",
      "['Al-Azhar University']\n",
      "['FARAI CHIDEYA']\n",
      "['\\\\epsilon']\n",
      "['Katherine Marshall Woods']\n",
      "['baby-shaking case']\n",
      "['CHIEF JUSTICE ROBERTS']\n",
      "['10 of 11']\n",
      "['Don Gonyea']\n"
     ]
    }
   ],
   "source": [
    "combined_data_test=combined_data[0:10]\n",
    "for i in combined_data_test:\n",
    "    print(i['answers'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f99310f",
   "metadata": {},
   "source": [
    "### The combined data saved to local environment for the later use"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "346560d6",
   "metadata": {},
   "source": [
    "## 2 Running the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51d5892e",
   "metadata": {},
   "source": [
    "### 2.1 Helper Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e7f3207",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "import collections\n",
    "\n",
    "def compute_f1(a_gold, a_pred):\n",
    "    gold_toks = word_tokenize(a_gold)\n",
    "    pred_toks = word_tokenize(a_pred)\n",
    "    common = collections.Counter(gold_toks) & collections.Counter(pred_toks)\n",
    "    num_same = sum(common.values())\n",
    "    \n",
    "    if len(gold_toks) == 0 or len(pred_toks) == 0:\n",
    "        # If either is no-answer, then F1 is 1 if they agree, 0 otherwise\n",
    "        return int(gold_toks == pred_toks)\n",
    "    \n",
    "    if num_same == 0:\n",
    "        return 0\n",
    "    \n",
    "    precision = 1.0 * num_same / len(pred_toks)\n",
    "    recall = 1.0 * num_same / len(gold_toks)\n",
    "    f1 = (2 * precision * recall) / (precision + recall)\n",
    "    return f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dd9eb283",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found model file at  E:/ggml-model-gpt4all-falcon-q4_0.bin\n"
     ]
    }
   ],
   "source": [
    "template = \"\"\"Use the following pieces of context to answer the question at the end. \n",
    "If you don't know the answer, just say that you don't know, don't try to make up an answer. \n",
    "Use three sentences maximum and keep the answer as concise as possible. \n",
    "Also provide me the source for your answer. Explain how to get the answer step by step.\n",
    "{context}\n",
    "Question: {question}\n",
    "Helpful Answer:\"\"\"\n",
    "QA_CHAIN_PROMPT = PromptTemplate.from_template(template)\n",
    "llm = GPT4All(model=\"E:/ggml-model-gpt4all-falcon-q4_0.bin\", max_tokens=2048)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8a325108",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found model file at  C:\\\\\\\\Users\\\\\\\\Administrator\\\\\\\\.cache\\\\\\\\gpt4all\\\\ggml-all-MiniLM-L6-v2-f16.bin\n",
      "Found model file at  C:\\\\\\\\Users\\\\\\\\Administrator\\\\\\\\.cache\\\\\\\\gpt4all\\\\ggml-all-MiniLM-L6-v2-f16.bin\n",
      "Found model file at  C:\\\\\\\\Users\\\\\\\\Administrator\\\\\\\\.cache\\\\\\\\gpt4all\\\\ggml-all-MiniLM-L6-v2-f16.bin\n",
      "Found model file at  C:\\\\\\\\Users\\\\\\\\Administrator\\\\\\\\.cache\\\\\\\\gpt4all\\\\ggml-all-MiniLM-L6-v2-f16.bin\n",
      "Found model file at  C:\\\\\\\\Users\\\\\\\\Administrator\\\\\\\\.cache\\\\\\\\gpt4all\\\\ggml-all-MiniLM-L6-v2-f16.bin\n",
      "Found model file at  C:\\\\\\\\Users\\\\\\\\Administrator\\\\\\\\.cache\\\\\\\\gpt4all\\\\ggml-all-MiniLM-L6-v2-f16.bin\n",
      "Found model file at  C:\\\\\\\\Users\\\\\\\\Administrator\\\\\\\\.cache\\\\\\\\gpt4all\\\\ggml-all-MiniLM-L6-v2-f16.bin\n",
      "Found model file at  C:\\\\\\\\Users\\\\\\\\Administrator\\\\\\\\.cache\\\\\\\\gpt4all\\\\ggml-all-MiniLM-L6-v2-f16.bin\n",
      "Found model file at  C:\\\\\\\\Users\\\\\\\\Administrator\\\\\\\\.cache\\\\\\\\gpt4all\\\\ggml-all-MiniLM-L6-v2-f16.bin\n",
      "Found model file at  C:\\\\\\\\Users\\\\\\\\Administrator\\\\\\\\.cache\\\\\\\\gpt4all\\\\ggml-all-MiniLM-L6-v2-f16.bin\n",
      "Found model file at  C:\\\\\\\\Users\\\\\\\\Administrator\\\\\\\\.cache\\\\\\\\gpt4all\\\\ggml-all-MiniLM-L6-v2-f16.bin\n",
      "Found model file at  C:\\\\\\\\Users\\\\\\\\Administrator\\\\\\\\.cache\\\\\\\\gpt4all\\\\ggml-all-MiniLM-L6-v2-f16.bin\n",
      "Found model file at  C:\\\\\\\\Users\\\\\\\\Administrator\\\\\\\\.cache\\\\\\\\gpt4all\\\\ggml-all-MiniLM-L6-v2-f16.bin\n",
      "Found model file at  C:\\\\\\\\Users\\\\\\\\Administrator\\\\\\\\.cache\\\\\\\\gpt4all\\\\ggml-all-MiniLM-L6-v2-f16.bin\n",
      "Found model file at  C:\\\\\\\\Users\\\\\\\\Administrator\\\\\\\\.cache\\\\\\\\gpt4all\\\\ggml-all-MiniLM-L6-v2-f16.bin\n",
      "Found model file at  C:\\\\\\\\Users\\\\\\\\Administrator\\\\\\\\.cache\\\\\\\\gpt4all\\\\ggml-all-MiniLM-L6-v2-f16.bin\n",
      "Found model file at  C:\\\\\\\\Users\\\\\\\\Administrator\\\\\\\\.cache\\\\\\\\gpt4all\\\\ggml-all-MiniLM-L6-v2-f16.bin\n",
      "Found model file at  C:\\\\\\\\Users\\\\\\\\Administrator\\\\\\\\.cache\\\\\\\\gpt4all\\\\ggml-all-MiniLM-L6-v2-f16.bin\n",
      "Found model file at  C:\\\\\\\\Users\\\\\\\\Administrator\\\\\\\\.cache\\\\\\\\gpt4all\\\\ggml-all-MiniLM-L6-v2-f16.bin\n",
      "Found model file at  C:\\\\\\\\Users\\\\\\\\Administrator\\\\\\\\.cache\\\\\\\\gpt4all\\\\ggml-all-MiniLM-L6-v2-f16.bin\n",
      "Found model file at  C:\\\\\\\\Users\\\\\\\\Administrator\\\\\\\\.cache\\\\\\\\gpt4all\\\\ggml-all-MiniLM-L6-v2-f16.bin\n",
      "Found model file at  C:\\\\\\\\Users\\\\\\\\Administrator\\\\\\\\.cache\\\\\\\\gpt4all\\\\ggml-all-MiniLM-L6-v2-f16.bin\n",
      "Found model file at  C:\\\\\\\\Users\\\\\\\\Administrator\\\\\\\\.cache\\\\\\\\gpt4all\\\\ggml-all-MiniLM-L6-v2-f16.bin\n",
      "Found model file at  C:\\\\\\\\Users\\\\\\\\Administrator\\\\\\\\.cache\\\\\\\\gpt4all\\\\ggml-all-MiniLM-L6-v2-f16.bin\n",
      "Found model file at  C:\\\\\\\\Users\\\\\\\\Administrator\\\\\\\\.cache\\\\\\\\gpt4all\\\\ggml-all-MiniLM-L6-v2-f16.bin\n",
      "Found model file at  C:\\\\\\\\Users\\\\\\\\Administrator\\\\\\\\.cache\\\\\\\\gpt4all\\\\ggml-all-MiniLM-L6-v2-f16.bin\n",
      "Found model file at  C:\\\\\\\\Users\\\\\\\\Administrator\\\\\\\\.cache\\\\\\\\gpt4all\\\\ggml-all-MiniLM-L6-v2-f16.bin\n",
      "Found model file at  C:\\\\\\\\Users\\\\\\\\Administrator\\\\\\\\.cache\\\\\\\\gpt4all\\\\ggml-all-MiniLM-L6-v2-f16.bin\n",
      "Found model file at  C:\\\\\\\\Users\\\\\\\\Administrator\\\\\\\\.cache\\\\\\\\gpt4all\\\\ggml-all-MiniLM-L6-v2-f16.bin\n",
      "Found model file at  C:\\\\\\\\Users\\\\\\\\Administrator\\\\\\\\.cache\\\\\\\\gpt4all\\\\ggml-all-MiniLM-L6-v2-f16.bin\n",
      "Found model file at  C:\\\\\\\\Users\\\\\\\\Administrator\\\\\\\\.cache\\\\\\\\gpt4all\\\\ggml-all-MiniLM-L6-v2-f16.bin\n",
      "Found model file at  C:\\\\\\\\Users\\\\\\\\Administrator\\\\\\\\.cache\\\\\\\\gpt4all\\\\ggml-all-MiniLM-L6-v2-f16.bin\n",
      "Found model file at  C:\\\\\\\\Users\\\\\\\\Administrator\\\\\\\\.cache\\\\\\\\gpt4all\\\\ggml-all-MiniLM-L6-v2-f16.bin\n",
      "Found model file at  C:\\\\\\\\Users\\\\\\\\Administrator\\\\\\\\.cache\\\\\\\\gpt4all\\\\ggml-all-MiniLM-L6-v2-f16.bin\n",
      "Found model file at  C:\\\\\\\\Users\\\\\\\\Administrator\\\\\\\\.cache\\\\\\\\gpt4all\\\\ggml-all-MiniLM-L6-v2-f16.bin\n",
      "Found model file at  C:\\\\\\\\Users\\\\\\\\Administrator\\\\\\\\.cache\\\\\\\\gpt4all\\\\ggml-all-MiniLM-L6-v2-f16.bin\n",
      "CPU times: total: 1h 33min 10s\n",
      "Wall time: 23min 44s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "answers_pairs=[]\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=200, chunk_overlap=0.1)\n",
    "\n",
    "\n",
    "for cov in combined_data:\n",
    "    all_splits = text_splitter.split_text(cov['text'])\n",
    "    vectorstore = Chroma.from_texts(texts=all_splits, embedding=GPT4AllEmbeddings())\n",
    "    qa_chain = RetrievalQA.from_chain_type(llm, retriever=vectorstore.as_retriever(), return_source_documents=True)\n",
    "    \n",
    "    question = cov['question']\n",
    "    docs = vectorstore.similarity_search(question)\n",
    "    predict = qa_chain({\"query\": question})\n",
    "    answers_pairs.append((cov['answers'],predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17a64054",
   "metadata": {},
   "source": [
    "### 2.1 Result Evaluation(F1 Score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d8e51af9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Which program does Suellen reference that shares its name with a snake?\n",
      "Predicted Answer:  Sueellen references the program called `snake` in her code.\n",
      "Actual Answer: Python\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Question: Which person is talking to the Chief Justice?\n",
      "Predicted Answer:  The person talking to the Chief Justice is Ms. Lee.\n",
      "Actual Answer: Mr. Kneedler\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Question: What is the name of the most important center of learning of Sunni Islam in the country where the pope is going to celebrate a mass tomorrow ?\n",
      "Predicted Answer:  The most important center of learning of Sunni Islam in the country where the pope is going to celebrate a mass tomorrow is Al Azhar University.\n",
      "Actual Answer: Al-Azhar University\n",
      "F1 Score: 0.0690\n",
      "\n",
      "Question: Who hosts NEWS & NOTES?\n",
      "Predicted Answer:  The context does not provide information about who hosts NEWS & NOTEs.\n",
      "Actual Answer: FARAI CHIDEYA\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Question: Which feature in DrRacket inserts an epsilon?\n",
      "Predicted Answer:  The `equal+hash` feature in DrRacket inserts an epsilon.\n",
      "Actual Answer: \\epsilon\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Question: What is the name of the clinical psychologist with the Psychological Group of Washington?\n",
      "Predicted Answer:  Taniesha Woods.\n",
      "Actual Answer: Katherine Marshall Woods\n",
      "F1 Score: 0.3333\n",
      "\n",
      "Question: what was the name of the case?\n",
      "Predicted Answer:  The case being referred to is the Baby-Shaking case.\n",
      "Actual Answer: baby-shaking case\n",
      "F1 Score: 0.1667\n",
      "\n",
      "Question: Who is the Chief Justice of  United States ?\n",
      "Predicted Answer:  The Chief Justice of the United States is currently John G. Roberts Jr.\n",
      "Actual Answer: CHIEF JUSTICE ROBERTS\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Question: What proportion of African American jurors were struck?\n",
      "Predicted Answer:  The proportion of African American jurors who were struck during the trial cannot be determined from the given context.\n",
      "Actual Answer: 10 of 11\n",
      "F1 Score: 0.0833\n",
      "\n",
      "Question: Which NPR reporter was traveling in South Carolina?\n",
      "Predicted Answer:  The context does not provide information about which NPR reporter was traveling in South Carolina.\n",
      "Actual Answer: Don Gonyea\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Question: Who is the only person that needs Denis O'Connell to sign a bilateral NDA?\n",
      "Predicted Answer:  The only person who needs Denis O'Connell to sign a bilateral ND\n",
      "Actual Answer: Leslie.Hansen\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Question: In which industry lynda need the survey about developers?\n",
      "Predicted Answer:  The survey is for developers in the tech industry.\n",
      "Actual Answer: tech industry\n",
      "F1 Score: 0.3333\n",
      "\n",
      "Question: What is the name of the petitioner in the case?\n",
      "Predicted Answer:  The petitioner in the case is not provided in the given context.\n",
      "Actual Answer: Mr. Lamken\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Question: Which act has a piece missing from it, according to the Circuit court?\n",
      "Predicted Answer:  The Circuit court believes that the FCPA does not provide protection for speech that is part of an employee's normal duties.\n",
      "Actual Answer: Federal Whistle-blower Protection Act\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Question: Which restatement section was based on injured party?\n",
      "Predicted Answer:  The reliance section, section three-24 says reliance is from the other for the injured party.\n",
      "Actual Answer: Section 324\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Question: How many months of unpaid leave does anyone with a permanent position have in Sweden ?\n",
      "Predicted Answer:  Anyone with a permanent position has a legal right to take up to 6 months of unpaid leave in Sweden.\n",
      "Actual Answer: six\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Question: What is the name of the amendment that requires reliability in the determination that death is an appropriate sentence ?\n",
      "Predicted Answer:  The amendment that requires reliability in the determination that death is an appropriate sentence is the Eighth Amendment.\n",
      "Actual Answer: Eighth Amendment\n",
      "F1 Score: 0.1905\n",
      "\n",
      "Question: Which month does Kate think the price of $292.50 possibly sounds right for?\n",
      "Predicted Answer:  It's difficult to determine which month the price of $292.50 possibly sounds right for without further context or information.\n",
      "Actual Answer: May\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Question: In which case Judge Weis gave his opinion ?\n",
      "Predicted Answer:  Judge Wei's opinion can be found in the case of Meritcare v. St. Paul.\n",
      "Actual Answer: Meritcare v. St. Paul\n",
      "F1 Score: 0.4000\n",
      "\n",
      "Question: Which company is giving the official confirmation letter for not to use their representative name?\n",
      "Predicted Answer:  It is not clear from the given context which company is giving the official confirmation letter for not to use their representative name.\n",
      "Actual Answer: Lehman Brothers Inc\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Question: Jason Rezaian wrote stories for which paper?\n",
      "Predicted Answer:  The context does not provide information about which paper Jason Rezaiana wrote stories for.\n",
      "Actual Answer: the Washington Post\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Question: Where does Deeanna want to move 'blueprints' into?\n",
      "Predicted Answer:  Deeanna wants to move 'blueprint's into 'ko\n",
      "Actual Answer: `koyo-lib`\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Question: What time is the OU-Enron game ?\n",
      "Predicted Answer:  The game starts at 7:00pm.\n",
      "Actual Answer: 700\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Question: What type of spy would have rights under regulations for handling secret contracts , Justice Clemmler says ?\n",
      "Predicted Answer:  It is unclear from the given context what type of spy would have rights under regulations for handling secret contracts.\n",
      "Actual Answer: were a party to a secret contract or at least a secret relationship\n",
      "F1 Score: 0.0588\n",
      "\n",
      "Question: Which types of networks are involved?\n",
      "Predicted Answer:  The given context does not provide specific information about the type of networks involved. However, based on the mention of a spreading-activation network and a network by which nodes support industry, it can be inferred that these networks may involve some form of social or economic interactions between nodes.\n",
      "Actual Answer: a spreading-activation network and a network by which nodes support the continued existence of other nodes\n",
      "F1 Score: 0.3768\n",
      "\n",
      "Question: Transactions will be between which two entities?\n",
      "Predicted Answer:  The context does not provide specific information about the parties involved in the transactions. However, it is mentioned that EnrOnine operates as a marketplace operator and customers can display products on <url> using the remote stack manager. It is also mentioned that Enron does not stand in the middle for credit and that they are a marketplace operator.\n",
      "Actual Answer: company offering product and customer\n",
      "F1 Score: 0.0290\n",
      "\n",
      "Question: What program allows the user to parallelize the tests and is recommended by Karoline?\n",
      "Predicted Answer:  pytest-parallel is recommended by Karoline for parallelization of tests.\n",
      "Actual Answer: pytest-parallel\n",
      "F1 Score: 0.1818\n",
      "\n",
      "Question: What does the Court say imposes restrictions on the discretion of police?\n",
      "Predicted Answer:  The Fourth Amendment imposes restrictions on the discretion of police officers and parole officers that are meaningful, as the Reyes Court said, there are restrictions on the timing, the frequency, the duration, and the oppressiveness of the search.\n",
      "Actual Answer: restrictions on the timing, the frequency, the duration, and the oppressiveness of the search\n",
      "F1 Score: 0.5574\n",
      "\n",
      "Question: Who is restrained in the circumstances of the trial?\n",
      "Predicted Answer:  The traffic offender who is restrained with non-visible restraints.\n",
      "Actual Answer: Mr. Deck\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Question: What kind of action is referenced by Scalia when the prosecutor has died?\n",
      "Predicted Answer:  The question does not provide specific information about the type of action being referred to.\n",
      "Actual Answer: habeas action\n",
      "F1 Score: 0.1111\n",
      "\n",
      "Question: Why will the process be legthier?\n",
      "Predicted Answer:  The process will be easier because it will be split into two separate approvals, one for Legal and another for MSRs Dilworth and Forshter. This will make it easier to move the process along without delays caused by overlapping approvals.\n",
      "Actual Answer: the legal due-diligence\n",
      "F1 Score: 0.0435\n",
      "\n",
      "Question: who is the first speaker?\n",
      "Predicted Answer:  The first speaker in the given context is Judge Wei Shing Lee.\n",
      "Actual Answer: MR. HURD\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Question: Which country has the new plane stuck?\n",
      "Predicted Answer:  The new plane is stuck in Iran.\n",
      "Actual Answer: Iran.\n",
      "F1 Score: 0.4000\n",
      "\n",
      "Question: Which names have Julia been experimenting more with capitalizing?\n",
      "Predicted Answer:  It is not clear from the given context which names Captain Obvious has experimented with capitalizing.\n",
      "Actual Answer: struct names\n",
      "F1 Score: 0.1053\n",
      "\n",
      "Question: What is the name of the casting director for the film Wendy Raquel Robinsondo worked on?\n",
      "Predicted Answer:  The name of the casting director for the film Wendy Raquel Robinson worked on is not provided in the given context.\n",
      "Actual Answer: Robi Reed\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Question: Which person is Neal hosting on the show?\n",
      "Predicted Answer:  Neal is hosting the show with Geoffrey Bennett, Tambae Obeinson, Katherine Marshall Woods, and Farai Chatzarakis.\n",
      "Actual Answer: Naomi Oreskes\n",
      "F1 Score: 0.0000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in answers_pairs:\n",
    "    f1_score = compute_f1(i[0][0],i[1]['result'])\n",
    "    print(f\"Question: {i[1]['query']}\")\n",
    "    print(f\"Predicted Answer: {i[1]['result']}\")\n",
    "    print(f\"Actual Answer: {i[0][0]}\")\n",
    "    print(f\"F1 Score: {f1_score:.4f}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1176c108",
   "metadata": {},
   "source": [
    "## 3 Attempt at Instruct Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "026f7929",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting InstructorEmbedding\n",
      "  Obtaining dependency information for InstructorEmbedding from https://files.pythonhosted.org/packages/6c/fc/64375441f43cc9ddc81f76a1a8f516e6d63f5b6ecb67fffdcddc0445f0d3/InstructorEmbedding-1.0.1-py2.py3-none-any.whl.metadata\n",
      "  Using cached InstructorEmbedding-1.0.1-py2.py3-none-any.whl.metadata (20 kB)\n",
      "Using cached InstructorEmbedding-1.0.1-py2.py3-none-any.whl (19 kB)\n",
      "Installing collected packages: InstructorEmbedding\n",
      "Successfully installed InstructorEmbedding-1.0.1\n"
     ]
    }
   ],
   "source": [
    "!pip install InstructorEmbedding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0335bf53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: torch in c:\\users\\administrator\\appdata\\roaming\\python\\python311\\site-packages (2.1.2)\n",
      "Requirement already satisfied: filelock in d:\\anaconda\\lib\\site-packages (from torch) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions in d:\\anaconda\\lib\\site-packages (from torch) (4.7.1)\n",
      "Requirement already satisfied: sympy in d:\\anaconda\\lib\\site-packages (from torch) (1.11.1)\n",
      "Requirement already satisfied: networkx in d:\\anaconda\\lib\\site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in d:\\anaconda\\lib\\site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: fsspec in d:\\anaconda\\lib\\site-packages (from torch) (2023.4.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in d:\\anaconda\\lib\\site-packages (from jinja2->torch) (2.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in d:\\anaconda\\lib\\site-packages (from sympy->torch) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "98f02eee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting sentence-transformers\n",
      "  Using cached sentence_transformers-2.2.2-py3-none-any.whl\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in d:\\anaconda\\lib\\site-packages (from sentence-transformers) (4.32.1)\n",
      "Requirement already satisfied: tqdm in d:\\anaconda\\lib\\site-packages (from sentence-transformers) (4.65.0)\n",
      "Requirement already satisfied: torch>=1.6.0 in c:\\users\\administrator\\appdata\\roaming\\python\\python311\\site-packages (from sentence-transformers) (2.1.2)\n",
      "Collecting torchvision (from sentence-transformers)\n",
      "  Obtaining dependency information for torchvision from https://files.pythonhosted.org/packages/f9/e6/3c821e7417acd82df89e39f09156ce80d58817b5b4b1ac5453b522bc5dd4/torchvision-0.16.2-cp311-cp311-win_amd64.whl.metadata\n",
      "  Using cached torchvision-0.16.2-cp311-cp311-win_amd64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: numpy in d:\\anaconda\\lib\\site-packages (from sentence-transformers) (1.24.3)\n",
      "Requirement already satisfied: scikit-learn in d:\\anaconda\\lib\\site-packages (from sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: scipy in d:\\anaconda\\lib\\site-packages (from sentence-transformers) (1.11.1)\n",
      "Requirement already satisfied: nltk in d:\\anaconda\\lib\\site-packages (from sentence-transformers) (3.8.1)\n",
      "Collecting sentencepiece (from sentence-transformers)\n",
      "  Using cached sentencepiece-0.1.99-cp311-cp311-win_amd64.whl (977 kB)\n",
      "Requirement already satisfied: huggingface-hub>=0.4.0 in d:\\anaconda\\lib\\site-packages (from sentence-transformers) (0.15.1)\n",
      "Requirement already satisfied: filelock in d:\\anaconda\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (3.9.0)\n",
      "Requirement already satisfied: fsspec in d:\\anaconda\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2023.4.0)\n",
      "Requirement already satisfied: requests in d:\\anaconda\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2.31.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in d:\\anaconda\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in d:\\anaconda\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (4.7.1)\n",
      "Requirement already satisfied: packaging>=20.9 in d:\\anaconda\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (23.1)\n",
      "Requirement already satisfied: sympy in d:\\anaconda\\lib\\site-packages (from torch>=1.6.0->sentence-transformers) (1.11.1)\n",
      "Requirement already satisfied: networkx in d:\\anaconda\\lib\\site-packages (from torch>=1.6.0->sentence-transformers) (3.1)\n",
      "Requirement already satisfied: jinja2 in d:\\anaconda\\lib\\site-packages (from torch>=1.6.0->sentence-transformers) (3.1.2)\n",
      "Requirement already satisfied: colorama in d:\\anaconda\\lib\\site-packages (from tqdm->sentence-transformers) (0.4.6)\n",
      "Requirement already satisfied: regex!=2019.12.17 in d:\\anaconda\\lib\\site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2022.7.9)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in d:\\anaconda\\lib\\site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.13.2)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in d:\\anaconda\\lib\\site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.3.2)\n",
      "Requirement already satisfied: click in d:\\anaconda\\lib\\site-packages (from nltk->sentence-transformers) (8.0.4)\n",
      "Requirement already satisfied: joblib in d:\\anaconda\\lib\\site-packages (from nltk->sentence-transformers) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in d:\\anaconda\\lib\\site-packages (from scikit-learn->sentence-transformers) (2.2.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in d:\\anaconda\\lib\\site-packages (from torchvision->sentence-transformers) (9.4.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in d:\\anaconda\\lib\\site-packages (from jinja2->torch>=1.6.0->sentence-transformers) (2.1.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\anaconda\\lib\\site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\anaconda\\lib\\site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\anaconda\\lib\\site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\anaconda\\lib\\site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2023.7.22)\n",
      "Requirement already satisfied: mpmath>=0.19 in d:\\anaconda\\lib\\site-packages (from sympy->torch>=1.6.0->sentence-transformers) (1.3.0)\n",
      "Using cached torchvision-0.16.2-cp311-cp311-win_amd64.whl (1.1 MB)\n",
      "Installing collected packages: sentencepiece, torchvision, sentence-transformers\n",
      "Successfully installed sentence-transformers-2.2.2 sentencepiece-0.1.99 torchvision-0.16.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8cb336e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: torch in c:\\users\\administrator\\appdata\\roaming\\python\\python311\\site-packages (2.1.2)\n",
      "Requirement already satisfied: torchvision in c:\\users\\administrator\\appdata\\roaming\\python\\python311\\site-packages (0.16.2)\n",
      "Collecting torchaudio\n",
      "  Obtaining dependency information for torchaudio from https://files.pythonhosted.org/packages/c9/c0/b738db223b85c0096e2c3b1aaa647419f9af68331f8ad09dba6a2d38136c/torchaudio-2.1.2-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading torchaudio-2.1.2-cp311-cp311-win_amd64.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: filelock in d:\\anaconda\\lib\\site-packages (from torch) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions in d:\\anaconda\\lib\\site-packages (from torch) (4.7.1)\n",
      "Requirement already satisfied: sympy in d:\\anaconda\\lib\\site-packages (from torch) (1.11.1)\n",
      "Requirement already satisfied: networkx in d:\\anaconda\\lib\\site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in d:\\anaconda\\lib\\site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: fsspec in d:\\anaconda\\lib\\site-packages (from torch) (2023.4.0)\n",
      "Requirement already satisfied: numpy in d:\\anaconda\\lib\\site-packages (from torchvision) (1.24.3)\n",
      "Requirement already satisfied: requests in d:\\anaconda\\lib\\site-packages (from torchvision) (2.31.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in d:\\anaconda\\lib\\site-packages (from torchvision) (9.4.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in d:\\anaconda\\lib\\site-packages (from jinja2->torch) (2.1.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\anaconda\\lib\\site-packages (from requests->torchvision) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\anaconda\\lib\\site-packages (from requests->torchvision) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\anaconda\\lib\\site-packages (from requests->torchvision) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\anaconda\\lib\\site-packages (from requests->torchvision) (2023.7.22)\n",
      "Requirement already satisfied: mpmath>=0.19 in d:\\anaconda\\lib\\site-packages (from sympy->torch) (1.3.0)\n",
      "Downloading torchaudio-2.1.2-cp311-cp311-win_amd64.whl (2.3 MB)\n",
      "   ---------------------------------------- 0.0/2.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/2.3 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.1/2.3 MB 787.7 kB/s eta 0:00:03\n",
      "   ----- ---------------------------------- 0.3/2.3 MB 2.5 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 1.0/2.3 MB 5.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  2.3/2.3 MB 11.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.3/2.3 MB 10.6 MB/s eta 0:00:00\n",
      "Installing collected packages: torchaudio\n",
      "Successfully installed torchaudio-2.1.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch torchvision torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "abcbab5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found model file at  E:/ggml-model-gpt4all-falcon-q4_0.bin\n"
     ]
    }
   ],
   "source": [
    "template = \"\"\"Use the following pieces of context to answer the question at the end. \n",
    "If you don't know the answer, just say that you don't know, don't try to make up an answer. \n",
    "Use three sentences maximum and keep the answer as concise as possible. \n",
    "Also provide me the source for your answer. Explain how to get the answer step by step.\n",
    "{context}\n",
    "Question: {question}\n",
    "Helpful Answer:\"\"\"\n",
    "QA_CHAIN_PROMPT = PromptTemplate.from_template(template)\n",
    "llm = GPT4All(model=\"E:/ggml-model-gpt4all-falcon-q4_0.bin\", max_tokens=2048)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4c16e926",
   "metadata": {},
   "outputs": [],
   "source": [
    "instruct_embedding_model_name = \"sentence-transformers/multi-qa-MiniLM-L6-cos-v1\"\n",
    "instruct_embedding_model_kwargs = {'device': 'cpu'}\n",
    "instruct_embedding_encode_kwargs = {'normalize_embeddings': True}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aa0c89ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\AppData\\Roaming\\Python\\Python311\\site-packages\\InstructorEmbedding\\instructor.py:7: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import trange\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load INSTRUCTOR_Transformer\n",
      "max_seq_length  512\n",
      "CPU times: total: 1h 25min 42s\n",
      "Wall time: 21min 18s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "answers_pairs=[]\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=200, chunk_overlap=0.1)\n",
    "\n",
    "word_embed = HuggingFaceInstructEmbeddings(\n",
    "    model_name=instruct_embedding_model_name,\n",
    "    model_kwargs=instruct_embedding_model_kwargs,\n",
    "    encode_kwargs=instruct_embedding_encode_kwargs,\n",
    "    embed_instruction=\"Represent the story for retrieval:\"\n",
    ")\n",
    "\n",
    "for cov in combined_data:\n",
    "    all_splits = text_splitter.split_text(cov['text'])\n",
    "    vectorstore = Chroma.from_texts(texts=all_splits, embedding=word_embed)\n",
    "    qa_chain = RetrievalQA.from_chain_type(llm, retriever=vectorstore.as_retriever(), return_source_documents=True)\n",
    "    \n",
    "    question = cov['question']\n",
    "    docs = vectorstore.similarity_search(question)\n",
    "    predict = qa_chain({\"query\": question})\n",
    "    answers_pairs.append((cov['answers'],predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b4e8d578",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Which program does Suellen reference that shares its name with a snake?\n",
      "Predicted Answer:  Sueltene does not mention any specific program with the same name as a snake.\n",
      "Actual Answer: Python\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Question: Which person is talking to the Chief Justice?\n",
      "Predicted Answer:  Ms. Lee is talking to the Chief Justice.\n",
      "Actual Answer: Mr. Kneedler\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Question: What is the name of the most important center of learning of Sunni Islam in the country where the pope is going to celebrate a mass tomorrow ?\n",
      "Predicted Answer:  The most important center of learning of Sunni Islam in the country where the pope is going to celebrate a mass tomorrow is Al Azhar University.\n",
      "Actual Answer: Al-Azhar University\n",
      "F1 Score: 0.0690\n",
      "\n",
      "Question: Who hosts NEWS & NOTES?\n",
      "Predicted Answer:  The context does not provide information on who hosts NEWS & NOTEs.\n",
      "Actual Answer: FARAI CHIDEYA\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Question: Which feature in DrRacket inserts an epsilon?\n",
      "Predicted Answer:  The feature in DrRacket that inserts an epsilon is the `@usefixures` fixture object.\n",
      "Actual Answer: \\epsilon\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Question: What is the name of the clinical psychologist with the Psychological Group of Washington?\n",
      "Predicted Answer:  Katherine Marshall Woods.\n",
      "Actual Answer: Katherine Marshall Woods\n",
      "F1 Score: 0.8571\n",
      "\n",
      "Question: what was the name of the case?\n",
      "Predicted Answer:  The case is called Davis v. United States.\n",
      "Actual Answer: baby-shaking case\n",
      "F1 Score: 0.1818\n",
      "\n",
      "Question: Who is the Chief Justice of  United States ?\n",
      "Predicted Answer:  The Chief Justice of the United States is currently John G. Roberts Jr.\n",
      "Actual Answer: CHIEF JUSTICE ROBERTS\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Question: What proportion of African American jurors were struck?\n",
      "Predicted Answer:  The context does not provide information on the proportion of African American jurors who were struck.\n",
      "Actual Answer: 10 of 11\n",
      "F1 Score: 0.1000\n",
      "\n",
      "Question: Which NPR reporter was traveling in South Carolina?\n",
      "Predicted Answer:  The context does not provide information about which NPR reporter was traveling in South Carolina.\n",
      "Actual Answer: Don Gonyea\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Question: Who is the only person that needs Denis O'Connell to sign a bilateral NDA?\n",
      "Predicted Answer:  The only person who needs Denis O'Connell to sign a bilateral ND\n",
      "Actual Answer: Leslie.Hansen\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Question: In which industry lynda need the survey about developers?\n",
      "Predicted Answer:  The survey about developers is relevant to the tech industry.\n",
      "Actual Answer: tech industry\n",
      "F1 Score: 0.3077\n",
      "\n",
      "Question: What is the name of the petitioner in the case?\n",
      "Predicted Answer:  The petitioner in the case is the person who initiated the appeal.\n",
      "Actual Answer: Mr. Lamken\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Question: Which act has a piece missing from it, according to the Circuit court?\n",
      "Predicted Answer:  The Circuit court believes that the Federal Employees Protection Act (FEPRA) has a gap in it, as interpreted by the Federal Circuit. This is because the Federal Circuit has construed the FEPRA to exclude protection for speech that is part of the employee's normal duties.\n",
      "Actual Answer: Federal Whistle-blower Protection Act\n",
      "F1 Score: 0.1091\n",
      "\n",
      "Question: Which restatement section was based on injured party?\n",
      "Predicted Answer:  The reliance section, section three-24 says reliance is from the other for the injured party.\n",
      "Actual Answer: Section 324\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Question: How many months of unpaid leave does anyone with a permanent position have in Sweden ?\n",
      "Predicted Answer:  Anyone with a permanent position in Sweden has the right to take up to 6 months of unpaid leave to launch a company without it affecting their employment.\n",
      "Actual Answer: six\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Question: What is the name of the amendment that requires reliability in the determination that death is an appropriate sentence ?\n",
      "Predicted Answer:  The Eighth Amendment requires reliability in the determination that death is an appropriate sentence.\n",
      "Actual Answer: Eighth Amendment\n",
      "F1 Score: 0.2353\n",
      "\n",
      "Question: Which month does Kate think the price of $292.50 possibly sounds right for?\n",
      "Predicted Answer:  It is unclear from the given context which month Kate thinks the price of $292.50 possibly sounds right for.\n",
      "Actual Answer: May\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Question: In which case Judge Weis gave his opinion ?\n",
      "Predicted Answer:  The case Judge Wei's opinion was given in is not provided in the given context.\n",
      "Actual Answer: Meritcare v. St. Paul\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Question: Which company is giving the official confirmation letter for not to use their representative name?\n",
      "Predicted Answer:  The company that is giving the official confirmation letter for not to use their representative name is \"Designa\".\n",
      "Actual Answer: Lehman Brothers Inc\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Question: Jason Rezaian wrote stories for which paper?\n",
      "Predicted Answer:  Jason Rezaian wrote stories for The Washington Post.\n",
      "Actual Answer: the Washington Post\n",
      "F1 Score: 0.3333\n",
      "\n",
      "Question: Where does Deeanna want to move 'blueprints' into?\n",
      "Predicted Answer:  Deeanna wants to move 'blueprint's into 'ko\n",
      "Actual Answer: `koyo-lib`\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Question: What time is the OU-Enron game ?\n",
      "Predicted Answer:  The game starts at 7:00pm.\n",
      "Actual Answer: 700\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Question: What type of spy would have rights under regulations for handling secret contracts , Justice Clemmler says ?\n",
      "Predicted Answer:  It is unclear from the given context what specific type of spy Justice Clemmer believes would have rights under regulations for handling secret contracts.\n",
      "Actual Answer: were a party to a secret contract or at least a secret relationship\n",
      "F1 Score: 0.0526\n",
      "\n",
      "Question: Which types of networks are involved?\n",
      "Predicted Answer:  The context mentions several types of networks, including a spreading-activation network, a network by which nodes support adopted by the legislature and internal executive branch directives taking into account the relative costs and benefits of certain types of regulation. There is also a model.rkt layer on top of graph that provides knowledge about nodeclasses and other elements of the spec.\n",
      "Actual Answer: a spreading-activation network and a network by which nodes support the continued existence of other nodes\n",
      "F1 Score: 0.3250\n",
      "\n",
      "Question: Transactions will be between which two entities?\n",
      "Predicted Answer:  The context does not provide specific information on which two entities will be involved in the transactions.\n",
      "Actual Answer: company offering product and customer\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Question: What program allows the user to parallelize the tests and is recommended by Karoline?\n",
      "Predicted Answer:  The program recommended by Karoline for parallelizing tests is pytest.\n",
      "Actual Answer: pytest-parallel\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Question: What does the Court say imposes restrictions on the discretion of police?\n",
      "Predicted Answer:  The Fourth Amendment imposes restrictions on the discretion of police officers and parole officers in their use of surveillance techniques.\n",
      "Actual Answer: restrictions on the timing, the frequency, the duration, and the oppressiveness of the search\n",
      "F1 Score: 0.2632\n",
      "\n",
      "Question: Who is restrained in the circumstances of the trial?\n",
      "Predicted Answer:  The defendant is restrained in the circumstances of the trial.\n",
      "Actual Answer: Mr. Deck\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Question: What kind of action is referenced by Scalia when the prosecutor has died?\n",
      "Predicted Answer:  The type of action referenced by Scalia when the prosecutor has died is a civil action for malicious prosecution.\n",
      "Actual Answer: habeas action\n",
      "F1 Score: 0.0909\n",
      "\n",
      "Question: Why will the process be legthier?\n",
      "Predicted Answer:  The process will be easier because it will be divided into two separate approval processes for legal and para-legal personnel, giving them more time to complete the process before a reference entity is used.\n",
      "Actual Answer: the legal due-diligence\n",
      "F1 Score: 0.1026\n",
      "\n",
      "Question: who is the first speaker?\n",
      "Predicted Answer:  The first speaker in the given context is not provided.\n",
      "Actual Answer: MR. HURD\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Question: Which country has the new plane stuck?\n",
      "Predicted Answer:  The new plane is stuck in Iran.\n",
      "Actual Answer: Iran.\n",
      "F1 Score: 0.4000\n",
      "\n",
      "Question: Which names have Julia been experimenting more with capitalizing?\n",
      "Predicted Answer:  It's unclear from the given context which names Captain Obvious has experimented with capitalizing.\n",
      "Actual Answer: struct names\n",
      "F1 Score: 0.1111\n",
      "\n",
      "Question: What is the name of the casting director for the film Wendy Raquel Robinsondo worked on?\n",
      "Predicted Answer:  The casting director for the film Wendy Raquel Robinson worked on is not provided in the given context.\n",
      "Actual Answer: Robi Reed\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Question: Which person is Neal hosting on the show?\n",
      "Predicted Answer:  Neal is hosting Geoffrey Bennett on the show.\n",
      "Actual Answer: Naomi Oreskes\n",
      "F1 Score: 0.0000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in answers_pairs:\n",
    "    f1_score = compute_f1(i[0][0],i[1]['result'])\n",
    "    print(f\"Question: {i[1]['query']}\")\n",
    "    print(f\"Predicted Answer: {i[1]['result']}\")\n",
    "    print(f\"Actual Answer: {i[0][0]}\")\n",
    "    print(f\"F1 Score: {f1_score:.4f}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf9ed449",
   "metadata": {},
   "source": [
    "## 4 Adding question embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f13ad78",
   "metadata": {},
   "source": [
    "### 4.1 GPT4ALL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1752f52d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found model file at  E:/ggml-model-gpt4all-falcon-q4_0.bin\n"
     ]
    }
   ],
   "source": [
    "template = \"\"\"Use the following pieces of context to answer the question at the end. \n",
    "If you don't know the answer, just say that you don't know, don't try to make up an answer. \n",
    "Use ten words maximum and keep the answer as concise as possible. \n",
    "{context}\n",
    "Question: {question}\n",
    "Helpful Answer:\"\"\"\n",
    "QA_CHAIN_PROMPT = PromptTemplate.from_template(template)\n",
    "llm = GPT4All(model=\"E:/ggml-model-gpt4all-falcon-q4_0.bin\", max_tokens=2048)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "544aeac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "instruct_embedding_model_name = \"sentence-transformers/multi-qa-MiniLM-L6-cos-v1\"\n",
    "instruct_embedding_model_kwargs = {'device': 'cpu'}\n",
    "instruct_embedding_encode_kwargs = {'normalize_embeddings': True}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4a8fce05",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "answers_pairs=[]\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=200, chunk_overlap=0.1)\n",
    "model_name = \"sentence-transformers/multi-qa-MiniLM-L6-cos-v1\"\n",
    "model_kwargs = {'device': 'cpu'}\n",
    "encode_kwargs = {'normalize_embeddings': True}\n",
    "\n",
    "def process_story_questions(combined_data, model_name, instruction):\n",
    "    word_embed = HuggingFaceInstructEmbeddings(\n",
    "        model_name=instruct_embedding_model_name,\n",
    "        model_kwargs=instruct_embedding_model_kwargs,\n",
    "        encode_kwargs=instruct_embedding_encode_kwargs,\n",
    "        embed_instruction=\"Represent the story for retrieval:\"\n",
    "    )\n",
    "\n",
    "    for cov in combined_data:\n",
    "        all_splits = text_splitter.split_text(cov['text'])\n",
    "        vectorstore = Chroma.from_texts(texts=all_splits, embedding=word_embed)\n",
    "        qa_chain = RetrievalQA.from_chain_type(llm, retriever=vectorstore.as_retriever(), return_source_documents=True)\n",
    "\n",
    "        question = cov['question']\n",
    "        hf_query_embs = HuggingFaceInstructEmbeddings(\n",
    "            model_name=instruct_embedding_model_name,\n",
    "            model_kwargs=instruct_embedding_model_kwargs,\n",
    "            encode_kwargs=instruct_embedding_encode_kwargs,\n",
    "            query_instruction=instruction\n",
    "        )\n",
    "        question_emb = hf_query_embs.embed_query(question)\n",
    "        docs = vectorstore.similarity_search_by_vector(question_emb)\n",
    "        predict = qa_chain({\"query\": question})\n",
    "        answers_pairs.append((cov['answers'],predict))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0f81beb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\AppData\\Roaming\\Python\\Python311\\site-packages\\InstructorEmbedding\\instructor.py:7: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import trange\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load INSTRUCTOR_Transformer\n",
      "max_seq_length  512\n",
      "load INSTRUCTOR_Transformer\n",
      "max_seq_length  512\n",
      "load INSTRUCTOR_Transformer\n",
      "max_seq_length  512\n",
      "load INSTRUCTOR_Transformer\n",
      "max_seq_length  512\n",
      "load INSTRUCTOR_Transformer\n",
      "max_seq_length  512\n",
      "load INSTRUCTOR_Transformer\n",
      "max_seq_length  512\n",
      "load INSTRUCTOR_Transformer\n",
      "max_seq_length  512\n",
      "load INSTRUCTOR_Transformer\n",
      "max_seq_length  512\n",
      "load INSTRUCTOR_Transformer\n",
      "max_seq_length  512\n",
      "load INSTRUCTOR_Transformer\n",
      "max_seq_length  512\n",
      "load INSTRUCTOR_Transformer\n",
      "max_seq_length  512\n",
      "load INSTRUCTOR_Transformer\n",
      "max_seq_length  512\n",
      "load INSTRUCTOR_Transformer\n",
      "max_seq_length  512\n",
      "load INSTRUCTOR_Transformer\n",
      "max_seq_length  512\n",
      "load INSTRUCTOR_Transformer\n",
      "max_seq_length  512\n",
      "load INSTRUCTOR_Transformer\n",
      "max_seq_length  512\n",
      "load INSTRUCTOR_Transformer\n",
      "max_seq_length  512\n",
      "load INSTRUCTOR_Transformer\n",
      "max_seq_length  512\n",
      "load INSTRUCTOR_Transformer\n",
      "max_seq_length  512\n",
      "load INSTRUCTOR_Transformer\n",
      "max_seq_length  512\n",
      "load INSTRUCTOR_Transformer\n",
      "max_seq_length  512\n",
      "load INSTRUCTOR_Transformer\n",
      "max_seq_length  512\n",
      "load INSTRUCTOR_Transformer\n",
      "max_seq_length  512\n",
      "load INSTRUCTOR_Transformer\n",
      "max_seq_length  512\n",
      "load INSTRUCTOR_Transformer\n",
      "max_seq_length  512\n",
      "load INSTRUCTOR_Transformer\n",
      "max_seq_length  512\n",
      "load INSTRUCTOR_Transformer\n",
      "max_seq_length  512\n",
      "load INSTRUCTOR_Transformer\n",
      "max_seq_length  512\n",
      "load INSTRUCTOR_Transformer\n",
      "max_seq_length  512\n",
      "load INSTRUCTOR_Transformer\n",
      "max_seq_length  512\n",
      "load INSTRUCTOR_Transformer\n",
      "max_seq_length  512\n",
      "load INSTRUCTOR_Transformer\n",
      "max_seq_length  512\n",
      "load INSTRUCTOR_Transformer\n",
      "max_seq_length  512\n",
      "load INSTRUCTOR_Transformer\n",
      "max_seq_length  512\n",
      "load INSTRUCTOR_Transformer\n",
      "max_seq_length  512\n",
      "load INSTRUCTOR_Transformer\n",
      "max_seq_length  512\n",
      "load INSTRUCTOR_Transformer\n",
      "max_seq_length  512\n",
      "CPU times: total: 1h 22min 37s\n",
      "Wall time: 20min 29s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model_name = \"sentence-transformers/multi-qa-MiniLM-L6-cos-v1\"\n",
    "instruction = \"Represent the story for retrieval:\" \n",
    "process_story_questions(combined_data, model_name, instruction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1211dbcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Which program does Suellen reference that shares its name with a snake?\n",
      "Predicted Answer:  Sueltene does not mention any specific program with the same name as a snake.\n",
      "Actual Answer: Python\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Retrieved Sentence(s):\n",
      "page_content=\"development&gt; dislike because of the magicnessyeah, I hate python, where is my `malloc()` ,stuck_out_tongue,Not really the same thingIn this case I'm talking about decorators that magically rewrite\"\n",
      "page_content=\"<code_snippet><@Collette> you can do this ,))Link?<<url>It's not the same.I guess of that list, plugins could be nicein older pytest versions this was the only way, but now you can do it implicitly\"\n",
      "page_content='too'\n",
      "page_content=\"They have only one thing in common, they're both test runners.it has some magic fixture stuff, which looks pretty but which I dislike because of the magicness. But I'm sure it can make for quick test\"\n",
      "\n",
      "Question: Which person is talking to the Chief Justice?\n",
      "Predicted Answer:  Ms. Lee is talking to the Chief Justice.\n",
      "Actual Answer: Mr. Kneedler\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Retrieved Sentence(s):\n",
      "page_content='rebuttal.Thank you, Ms. Lee. Mr. Kneedler.Mr. Chief Justice, and may it please the Court, Much of the work of public employees is performed by speaking or writing, and much of that work concerns'\n",
      "page_content='interpose the first amendment in that relationship between supervisor and subordinate or otherwise to regulate the internal affairs of the executive branch. That is the function of civil service laws'\n",
      "page_content=\"matters of public interest. Under the Ninth Circuit's decision, public employees engaged in such work have at least a presumptive first amendment right to perform their jobs as they see fit. That\"\n",
      "page_content='that supervisors in the executive branch be able to control and direct the work of their subordinates. The first amendment, which was adopted just a few years after the Constitution, was not meant to'\n",
      "\n",
      "Question: What is the name of the most important center of learning of Sunni Islam in the country where the pope is going to celebrate a mass tomorrow ?\n",
      "Predicted Answer:  The most important center of learning of Sunni Islam in the country where the pope is going to celebrate a mass tomorrow is Al Azhar University.\n",
      "Actual Answer: Al-Azhar University\n",
      "F1 Score: 0.0690\n",
      "\n",
      "Retrieved Sentence(s):\n",
      "page_content=\"learning of Sunni Islam. And he and the pope have met several times, and they've established a very good relationship.OK. So it's an opportunity for the pope to reach out to Muslims but also speak\"\n",
      "page_content='are already describing it as the biggest public display of Christian worship in the Islamic heartland because, although the UAE prides itself to be a haven of tolerance, Islam is the official'\n",
      "page_content=\"humanitarian crisis in the world. There's a Saudi-led intervention there. And the Saudi coalition includes the United Arab Emirates. UAE warplanes have flown over Yemen dropping bombs. Is the pope\"\n",
      "page_content='directly to those 1 million Catholics we just mentioned.Absolutely. Tomorrow he is going to celebrate a mass in a large stadium. There are about 135,000 people who are expected, and some people here'\n",
      "\n",
      "Question: Who hosts NEWS & NOTES?\n",
      "Predicted Answer:  The context does not provide information on who hosts NEWS & NOTEs.\n",
      "Actual Answer: FARAI CHIDEYA\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Retrieved Sentence(s):\n",
      "page_content=\"Here at NEWS & NOTES, we have our own 40 acres of the blogosphere, News & Views. With more on our conversation, that means us here and you joining us online, we've got NEWS & NOTES Web producer\"\n",
      "page_content=\"Well, he's been invited to a big interreligious event taking place later today. It's part of an initiative aimed at promoting a moderate Islam and to counter religious fanaticism. For Francis, it's\"\n",
      "page_content=\"Geoffrey Bennett.Hey, Geoff.Hello, Farai.So I understand that the future of black CEOs has become a hot topic. Last week, Stan O'Neal stepped down from Merrill Lynch, and this week, Time Warner\"\n",
      "page_content='directly to those 1 million Catholics we just mentioned.Absolutely. Tomorrow he is going to celebrate a mass in a large stadium. There are about 135,000 people who are expected, and some people here'\n",
      "\n",
      "Question: Which feature in DrRacket inserts an epsilon?\n",
      "Predicted Answer:  The feature in DrRacket that inserts an epsilon is the `@usefixures` fixture object.\n",
      "Actual Answer: \\epsilon\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Retrieved Sentence(s):\n",
      "page_content='of redrawing for wheel events, and it works well for me.Huh. Using \\\\epsilon in DrRacket inserts an epsilon as expected. But if I copy paste it - I get a prompt to normalize the inserted string - and'\n",
      "page_content='can actually _use_ fixture objects in the test function, while `@usefixtures` is just, well, \"enabling\" fixtures for that test function'\n",
      "page_content=\"flaw in the way Racketâ€™s language stack works. But it basically means you want to do as much in the expander as you can, and as little in the reader.okay this all makes sense againit's hard to come\"\n",
      "page_content='treated the same way as a program you wrote yourself.But after the reader finishes, then the macroexpander gets to transform the program, and it enforces hygiene.I think this is, in some respects, a'\n",
      "\n",
      "Question: What is the name of the clinical psychologist with the Psychological Group of Washington?\n",
      "Predicted Answer:  Katherine Marshall Woods.\n",
      "Actual Answer: Katherine Marshall Woods\n",
      "F1 Score: 0.8571\n",
      "\n",
      "Retrieved Sentence(s):\n",
      "page_content=\"associate at the National Center for Children and Poverty, joined us from her office in New York City. Still with us here in the Studio 3A is Katherine Marshall Woods, who's a clinical psychologist\"\n",
      "page_content=\"with the Psychological Group of Washington. And when she's talking about those people going into that situation - that's you she was talking about, right?It is, actually. Many times, I do go into\"\n",
      "page_content='in the classroom. So there is a need for the mental health consultation.Well, Taniesha Woods, thanks very much for your time today. We appreciate it.Thank you.Taniesha Woods, senior research'\n",
      "page_content='with Head Start in being able to provide consultation services as well as being able to provide psychological testing for children who were at risk of being identified with learning disabilities and'\n",
      "\n",
      "Question: what was the name of the case?\n",
      "Predicted Answer:  The case is called Davis v. United States.\n",
      "Actual Answer: baby-shaking case\n",
      "F1 Score: 0.1818\n",
      "\n",
      "Retrieved Sentence(s):\n",
      "page_content='determinations, but --But the example that Justice Kennedy gave you was such a determination.I -- I think, though -- I -- I suppose that would depend on the nature of the specific evidence at issue.'\n",
      "page_content=\"to conclude that the evidence concerning the time of death was -- was credible, was accurate?I -- I think, Your Honor, that the trial judge found that -- that there simply wasn't a dispute about\"\n",
      "page_content='adopted by the legislature and internal executive branch directives taking into account the relative costs and benefits of certain types of regulation. And finally --'\n",
      "page_content=\"that, that -- that the -- that there wasn't enough. And so it was fine to look at the State's case. And I would urge the Court --But there is a dispute here as to the forensic evidence. The\"\n",
      "\n",
      "Question: Who is the Chief Justice of  United States ?\n",
      "Predicted Answer:  The Chief Justice of the United States is currently John G. Roberts Jr.\n",
      "Actual Answer: CHIEF JUSTICE ROBERTS\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Retrieved Sentence(s):\n",
      "page_content='rebuttal.Thank you, Ms. Lee. Mr. Kneedler.Mr. Chief Justice, and may it please the Court, Much of the work of public employees is performed by speaking or writing, and much of that work concerns'\n",
      "page_content='interpose the first amendment in that relationship between supervisor and subordinate or otherwise to regulate the internal affairs of the executive branch. That is the function of civil service laws'\n",
      "page_content=\"credibility determination, wouldn't he? He would be deciding an issue that normally would be submitted to the jury.It's not our position, Your Honor, that -- that the trial court can make credibility\"\n",
      "page_content='that supervisors in the executive branch be able to control and direct the work of their subordinates. The first amendment, which was adopted just a few years after the Constitution, was not meant to'\n",
      "\n",
      "Question: What proportion of African American jurors were struck?\n",
      "Predicted Answer:  The context does not provide information on the proportion of African American jurors who were struck.\n",
      "Actual Answer: 10 of 11\n",
      "F1 Score: 0.1000\n",
      "\n",
      "Retrieved Sentence(s):\n",
      "page_content='American jurors struck. We have the lawyers doing the questioning, trick questions, loaded questions, complicated questions. We have the external evidence of the Dallas manual recommending'\n",
      "page_content=\"transcript, California law that had talked about jury balances. It's good to have young and old. It's good to have different races. I agree. You're absolutely right. J.E.B. v. Alabama had occurred a\"\n",
      "page_content=\"discriminatory strikes. We have the cards with race written on them. Here, we have a very brief, quick proceeding. The judge is asking the questions and really resisting lawyers' attempts to add to\"\n",
      "page_content=\"inquiries, say that he accepts her non-racial reasons. Counsel for respondent does a lot to compare to Miller-El and so perhaps it's worth just distinguishing briefly. There we have 10 of 11 African\"\n",
      "\n",
      "Question: Which NPR reporter was traveling in South Carolina?\n",
      "Predicted Answer:  The context does not provide information about which NPR reporter was traveling in South Carolina.\n",
      "Actual Answer: Don Gonyea\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Retrieved Sentence(s):\n",
      "page_content=\"that, that -- that the -- that there wasn't enough. And so it was fine to look at the State's case. And I would urge the Court --But there is a dispute here as to the forensic evidence. The\"\n",
      "page_content=\"associate at the National Center for Children and Poverty, joined us from her office in New York City. Still with us here in the Studio 3A is Katherine Marshall Woods, who's a clinical psychologist\"\n",
      "page_content=\"place? I can't figure it out.Okay. Yes. During the judicial voir dire.Yes, I have that in front of me.And --What was the statement that the judge made in respect to which the juror is supposed to\"\n",
      "page_content=\"you're right. I mean, it's one where -- it doesn't say in the record eye-rolling.And it actually says it wasn't a question. It was a statement, and that's why I can't figure it out.It -- it seems to\"\n",
      "\n",
      "Question: Who is the only person that needs Denis O'Connell to sign a bilateral NDA?\n",
      "Predicted Answer:  The only person who needs Denis O'Connell to sign a bilateral ND\n",
      "Actual Answer: Leslie.Hansen\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Retrieved Sentence(s):\n",
      "page_content='has been limited to this single NDA.)  If you feel that this document\\nrequires our review instead, please let me know.\\nRegards,'\n",
      "page_content='Leslie,\\nCraig Chaney tells me that you have been looking at these documents.\\nThey need to be signed in the UK for tax reasons.'\n",
      "page_content='of comments, the maximum term that I have authority to approve is 2 years for\\na bilateral NDA.  If I2 insists on 3 years, I must obtain approval from Mark'\n",
      "page_content='Can you therefore send confirmation to Denis that you are happy with them so\\nhe can initial them and I will then get them signed.'\n",
      "\n",
      "Question: In which industry lynda need the survey about developers?\n",
      "Predicted Answer:  The survey about developers is relevant to the tech industry.\n",
      "Actual Answer: tech industry\n",
      "F1 Score: 0.3077\n",
      "\n",
      "Retrieved Sentence(s):\n",
      "page_content='Iâ€™m a UX design student working on a developersâ€™ career advice project and I would really appreciate if you could take 1 minute and help me participate in this survey about developers in tech'\n",
      "page_content='has been limited to this single NDA.)  If you feel that this document\\nrequires our review instead, please let me know.\\nRegards,'\n",
      "page_content='industry. Here is the link <<url>'\n",
      "page_content=\"associate at the National Center for Children and Poverty, joined us from her office in New York City. Still with us here in the Studio 3A is Katherine Marshall Woods, who's a clinical psychologist\"\n",
      "\n",
      "Question: What is the name of the petitioner in the case?\n",
      "Predicted Answer:  The petitioner in the case is the person who initiated the appeal.\n",
      "Actual Answer: Mr. Lamken\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Retrieved Sentence(s):\n",
      "page_content=\"California, States -- localities have the option of having the appeal go to the local legislature. That appeal is then reviewed -- is then determined. And finally, once you've gone through that\"\n",
      "page_content=\"place? I can't figure it out.Okay. Yes. During the judicial voir dire.Yes, I have that in front of me.And --What was the statement that the judge made in respect to which the juror is supposed to\"\n",
      "page_content=\"I think it suggests how vital it is to rely on the trial court judge to make some credibility determination. He's there and sees the district attorney and tries to, after making appropriate\"\n",
      "page_content='American jurors struck. We have the lawyers doing the questioning, trick questions, loaded questions, complicated questions. We have the external evidence of the Dallas manual recommending'\n",
      "\n",
      "Question: Which act has a piece missing from it, according to the Circuit court?\n",
      "Predicted Answer:  The Circuit court believes that the Federal Employees Protection Act (FEPRA) has a gap in it, as interpreted by the Federal Circuit. This is because the Federal Circuit has construed the FEPRA to exclude protection for speech that is part of the employee's normal duties.\n",
      "Actual Answer: Federal Whistle-blower Protection Act\n",
      "F1 Score: 0.1091\n",
      "\n",
      "Retrieved Sentence(s):\n",
      "page_content=\"that statute has a gaping hole in it, as construed by the Federal Circuit, because the Federal Circuit has construed it to exclude protection for speech that is part of the employee's normal duties.\"\n",
      "page_content='--Congress wanted to substitute a Federal judgment for the judgment of the States where it said so. And the reason you know that is because that is what is consistent with the purpose of the act and'\n",
      "page_content=\"precedents construing section 103 and its common law predecessors. With regard to the kind of bias Your Honor is talking about, this Court's precedents provide a wealth of mechanisms for protecting\"\n",
      "page_content=\"work is performed. That is a basic rule of agency law, and insofar as Federal employees are concerned, it's a basic rule of our constitutional structure. Article II of the Constitution gives the\"\n",
      "\n",
      "Question: Which restatement section was based on injured party?\n",
      "Predicted Answer:  The reliance section, section three-24 says reliance is from the other for the injured party.\n",
      "Actual Answer: Section 324\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Retrieved Sentence(s):\n",
      "page_content='reliance exists. And I have to correct the Solicitor General. The reliance does not merely come from the injured party. The restatement section, section three- -- or the restatement section 324 says'\n",
      "page_content=\"reliance is from the other for the injured party. So, in this case --Well, doesn't that make it a contract case? If you're talking about the party who's contracted with, say, a private inspector -- I\"\n",
      "page_content=\"because ---- claimed would occur.-- they're addressed -- is it -- they're addressed under State and Federal whistle-blower laws, or --No, that's -- actually gets me back to the second part of Justice\"\n",
      "page_content='which may, in fact, speak to issues that may, in fact, address Arizona law on Good Samaritan, for instance -- the issue of whether, under Arizona law, a duty was assumed, the issue of whether'\n",
      "\n",
      "Question: How many months of unpaid leave does anyone with a permanent position have in Sweden ?\n",
      "Predicted Answer:  Anyone with a permanent position in Sweden has the right to take up to 6 months of unpaid leave to launch a company without it affecting their employment.\n",
      "Actual Answer: six\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Retrieved Sentence(s):\n",
      "page_content=\"beginning.Her story isn't unusual in Sweden, where anyone with a permanent position has a legal right to take unpaid leave for six months to launch a company, providing it doesn't compete with their\"\n",
      "page_content=\"making it more profitable, but you can also promote entrepreneurship by making it less insecure.Global observers argue that one of the benefits of Sweden's unpaid leave system is that it recognizes\"\n",
      "page_content='usual employer.To find out more, I braved the snow and made a visit to Samuel Engblom at the Swedish Confederation for Professional Employees, which represents white-collar workers. Hi there.Hello,'\n",
      "page_content=\"Well, it would be assigned job duties, things that normally the employer would take into consideration for things like terminating or promoting. I'd like to reserve the remainder of my time for\"\n",
      "\n",
      "Question: What is the name of the amendment that requires reliability in the determination that death is an appropriate sentence ?\n",
      "Predicted Answer:  The Eighth Amendment requires reliability in the determination that death is an appropriate sentence.\n",
      "Actual Answer: Eighth Amendment\n",
      "F1 Score: 0.2353\n",
      "\n",
      "Retrieved Sentence(s):\n",
      "page_content=\"jurisdictional issues, I will proceed to the merits. To pick up on some of the things that were said during Attorney General Kline's argument, the Eighth Amendment requires reliability in the\"\n",
      "page_content='determination that death is an appropriate sentence. And at the selection stage, the question is whether the jury has made a reliable, collective, responsible decision based upon the unique'\n",
      "page_content='circumstances of the individual defendant that death is an appropriate sentence and that this defendant is particularly culpable in a way that distinguishes him from the mass of death-eligible'\n",
      "page_content=\"whether the jury did decree death by equipoise or not. Death sentences must be rationally reviewable. And when we look at the -- at a death sentence that's been pronounced in Kansas, we can't\"\n",
      "\n",
      "Question: Which month does Kate think the price of $292.50 possibly sounds right for?\n",
      "Predicted Answer:  It's unclear which specific month Kate believes the price of $292.50 sounds right for.\n",
      "Actual Answer: May\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Retrieved Sentence(s):\n",
      "page_content=\"said a price like $292.50 doesn't sound right for Sept. - possibly May?This is what amerex is showing and this is what I have confirmed.This is what amerex is showing and this is what I have\"\n",
      "page_content='Amerex is showing a deal on their checkout I did not verbal\\nEnron buys from Aquila Sept. 01 PV 25 mw peak hrs at $292.50Mike did a deal with these terms but a price of 380 - deal is #571917. But he'\n",
      "page_content=\"Enron buys from Aquila Sept. 01 PV 25 mw peak hrs at $292.50Kate, what's the status?\"\n",
      "page_content=\"have rolled her eyes?The district attorney simply says with one of the questions to which you -- the prospective --Which question?It's unclear.So the reason I can't find it out is none of us know.No,\"\n",
      "\n",
      "Question: In which case Judge Weis gave his opinion ?\n",
      "Predicted Answer:  The case Judge Wei's opinion was given in is not provided in the given context.\n",
      "Actual Answer: Meritcare v. St. Paul\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Retrieved Sentence(s):\n",
      "page_content='opinions opposing our view of -- of this position.He was the chair of the --He was. And Judge Weis, even in his own opinion, acknowledges that his subcommittee that wrote the language intended to'\n",
      "page_content=\"article.Well, Your Honor, respectfully, what we do have is undisputed fact here because if you see Judge Weis' conclusion, for example, Judge Weis is one of the people who has adopted one of the\"\n",
      "page_content=\"credibility determination, wouldn't he? He would be deciding an issue that normally would be submitted to the jury.It's not our position, Your Honor, that -- that the trial court can make credibility\"\n",
      "page_content=\"I think it suggests how vital it is to rely on the trial court judge to make some credibility determination. He's there and sees the district attorney and tries to, after making appropriate\"\n",
      "\n",
      "Question: Which company is giving the official confirmation letter for not to use their representative name?\n",
      "Predicted Answer:  The company that is giving the official confirmation letter for not to use their representative name is \"Designa\".\n",
      "Actual Answer: Lehman Brothers Inc\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Retrieved Sentence(s):\n",
      "page_content='This message is intended only for the personal and confidential use of the\\ndesignated recipient(s) named above.  If you are not the intended'\n",
      "page_content='Leslie,\\nCraig Chaney tells me that you have been looking at these documents.\\nThey need to be signed in the UK for tax reasons.'\n",
      "page_content='subsidiaries or affiliates.  Email transmission cannot be guaranteed to be\\nsecure or error-free.  Therefore, we do not represent that this'\n",
      "page_content='Many thanks,\\nRichard\\n\\n\\n\\nThe only changes I have made here are\\n\\nAnnouncements\\nAny announcement made related to this agreement must be approved in advance\\nin writing by both parties.'\n",
      "\n",
      "Question: Jason Rezaian wrote stories for which paper?\n",
      "Predicted Answer:  Jason Rezaian wrote stories for The Washington Post.\n",
      "Actual Answer: the Washington Post\n",
      "F1 Score: 0.3333\n",
      "\n",
      "Retrieved Sentence(s):\n",
      "page_content=\"but I remember being slightly at odds with the article only because unless I am running a site where blogging (with multiple admin levels) is the main objective, I don't feel like I need to resort to\"\n",
      "page_content='Leslie,\\nCraig Chaney tells me that you have been looking at these documents.\\nThey need to be signed in the UK for tax reasons.'\n",
      "page_content='know, were able to print out some emails. And they would bring them into the interrogation room with captions highlighted, some of my stories that appeared in The Washington Post and the most'\n",
      "page_content='I would appreciate it if you could facilitate this document through the\\nrequired processes.  lelsie just needs to review the changes that London made'\n",
      "\n",
      "Question: Where does Deeanna want to move 'blueprints' into?\n",
      "Predicted Answer:  Deeanna wants to move 'blueprint's into 'ko\n",
      "Actual Answer: `koyo-lib`\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Retrieved Sentence(s):\n",
      "page_content=\"of `blueprints` is outside of the package's installation path so I get this error after I install the package,\"\n",
      "page_content='If I move blueprints inside `koyo-lib`, then that causes problems as well because `blueprints` contains racket code (and koyo-lib is declared as a multi-collection package (though I could change it'\n",
      "page_content='Leslie,\\nCraig Chaney tells me that you have been looking at these documents.\\nThey need to be signed in the UK for tax reasons.'\n",
      "page_content=\"to a single collection package, but I'm not sure that would help)).So what I would like to do is move `blueprints` into `koyo-lib` but somehow tell `raco pkg` that it should ignore the `blueprints`\"\n",
      "\n",
      "Question: What time is the OU-Enron game ?\n",
      "Predicted Answer:  The game starts at 7:00pm.\n",
      "Actual Answer: 700\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Retrieved Sentence(s):\n",
      "page_content=\"Our game is at 700 this week.  We play the other Enron team.  Please let me\\nknow whether or not you will attend.i am in.I'm there.  What do you think about OU??  I think it will be a tough game but\"\n",
      "page_content=\"Enron buys from Aquila Sept. 01 PV 25 mw peak hrs at $292.50Kate, what's the status?\"\n",
      "page_content=\"Agreement.  Wouldn't it be more appropriate for EnronCredit.com's lawyers in\\nLondon to sign off on this Agreement.  (My involvement with EnronCredit.com\"\n",
      "page_content='1,000,000 shares yesterday.  As discussed, we currently have approval to\\nexecute 3 month forwards on an additional 1,150,000 shares.'\n",
      "\n",
      "Question: What type of spy would have rights under regulations for handling secret contracts , Justice Clemmler says ?\n",
      "Predicted Answer:  It is unclear from the given context what specific type of spy Justice Clemmer believes would have rights under regulations for handling secret contracts.\n",
      "Actual Answer: were a party to a secret contract or at least a secret relationship\n",
      "F1 Score: 0.0526\n",
      "\n",
      "Retrieved Sentence(s):\n",
      "page_content='would have rights under those regulations, and the very idea of walking into court and asserting your rights as an alleged spy is inconsistent with the entire relationship and the contract that gave'\n",
      "page_content=\"because their -- their -- still their claim to having any entitlement under those rules at all would -- I mean, you know, total strangers don't have rights under those regulations. Alleged spies\"\n",
      "page_content=\"statement even if it's classified. So I think on the authority of Weinberger as well, the very fact that there are internal regulations on a subject, the entire subject matter of which is secret,\"\n",
      "page_content=\"regulations for handling secret contracts. So unless one can allege that they were a party to a secret contract or at least a secret relationship, there's no point in that individual even being in a\"\n",
      "\n",
      "Question: Which types of networks are involved?\n",
      "Predicted Answer:  The context mentions several types of networks, including a spreading-activation network, a network by which nodes support adopted by the legislature and internal executive branch directives taking into account the relative costs and benefits of certain types of regulation. There is also a model.rkt layer on top of graph that provides knowledge about nodeclasses and other elements of the spec.\n",
      "Actual Answer: a spreading-activation network and a network by which nodes support the continued existence of other nodes\n",
      "F1 Score: 0.3250\n",
      "\n",
      "Retrieved Sentence(s):\n",
      "page_content='been tagged, ask if a node could be tagged with a certain (not yet created) tag, etc. There are some other things, too, involving a spreading-activation network and a network by which nodes support'\n",
      "page_content='adopted by the legislature and internal executive branch directives taking into account the relative costs and benefits of certain types of regulation. And finally --'\n",
      "page_content='Then there\\'s `model.rkt`, which provides a layer on top of `graph`. `model.rkt` knows about nodeclasses and other elements of the spec. You can tell it to \"tag\" some nodes, ask it if some nodes have'\n",
      "page_content='subsidiaries or affiliates.  Email transmission cannot be guaranteed to be\\nsecure or error-free.  Therefore, we do not represent that this'\n",
      "\n",
      "Question: Transactions will be between which two entities?\n",
      "Predicted Answer:  The context does not provide specific information on which two entities will be involved in the transactions.\n",
      "Actual Answer: company offering product and customer\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Retrieved Sentence(s):\n",
      "page_content=\"With regard to the Relationship Terms, this is the first I've ever seen of\\nthis document and I'm not sure if I'm the appropriate person to review the\"\n",
      "page_content='although I am sure that the Court, in deliberations, will be considering the several jurisdictional issues which were briefed and argued earlier in the term. And if there are no questions on those'\n",
      "page_content=\"regulations for handling secret contracts. So unless one can allege that they were a party to a secret contract or at least a secret relationship, there's no point in that individual even being in a\"\n",
      "page_content=\"reliance is from the other for the injured party. So, in this case --Well, doesn't that make it a contract case? If you're talking about the party who's contracted with, say, a private inspector -- I\"\n",
      "\n",
      "Question: What program allows the user to parallelize the tests and is recommended by Karoline?\n",
      "Predicted Answer:  The program recommended by Karoline for parallelizing tests is pytest.\n",
      "Actual Answer: pytest-parallel\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Retrieved Sentence(s):\n",
      "page_content='goodWhat does that do?yeah that and pytest-parallel are worth a look.  basically they allow you to paralelize your testsOkayWill definitely look into thoseThanks <@Eliana> <@Karoline> ,taco,Having a'\n",
      "page_content='matlab?Parallelization<@Karoline>For the former I can specifically run test cases covering themare you using pytest?  there are a couple of plugins for parallelizationYes pytestpytest-xdist is pretty'\n",
      "page_content=\"They have only one thing in common, they're both test runners.it has some magic fixture stuff, which looks pretty but which I dislike because of the magicness. But I'm sure it can make for quick test\"\n",
      "page_content='has been limited to this single NDA.)  If you feel that this document\\nrequires our review instead, please let me know.\\nRegards,'\n",
      "\n",
      "Question: What does the Court say imposes restrictions on the discretion of police?\n",
      "Predicted Answer:  The Fourth Amendment imposes restrictions on the discretion of police officers and parole officers in their use of surveillance techniques.\n",
      "Actual Answer: restrictions on the timing, the frequency, the duration, and the oppressiveness of the search\n",
      "F1 Score: 0.2632\n",
      "\n",
      "Retrieved Sentence(s):\n",
      "page_content='believe the Fourth Amendment does impose -- the Fourth Amendment itself imposes restrictions on the discretion of police officers and parole officers that are meaningful, that -- as the Reyes Court'\n",
      "page_content='said, there are restrictions on the timing, the frequency, the duration, and the oppressiveness of the search. So, police officers and parole officers are on notice that courts will review'\n",
      "page_content='would have rights under those regulations, and the very idea of walking into court and asserting your rights as an alleged spy is inconsistent with the entire relationship and the contract that gave'\n",
      "page_content=\"because their -- their -- still their claim to having any entitlement under those rules at all would -- I mean, you know, total strangers don't have rights under those regulations. Alleged spies\"\n",
      "\n",
      "Question: Who is restrained in the circumstances of the trial?\n",
      "Predicted Answer:  The defendant is restrained in the circumstances of the trial.\n",
      "Actual Answer: Mr. Deck\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Retrieved Sentence(s):\n",
      "page_content=\"credibility determination, wouldn't he? He would be deciding an issue that normally would be submitted to the jury.It's not our position, Your Honor, that -- that the trial court can make credibility\"\n",
      "page_content=\"doesn't give rise to judicially enforceable rights. If there are no further questions, I'd like to reserve the time for rebuttal.\"\n",
      "page_content='defendant being relevancy for introduction. And then, they are instructed to consider whether the State has proven, beyond a reasonable doubt, that the mitigating factors do not outweigh the'\n",
      "page_content=\"I think it suggests how vital it is to rely on the trial court judge to make some credibility determination. He's there and sees the district attorney and tries to, after making appropriate\"\n",
      "\n",
      "Question: What kind of action is referenced by Scalia when the prosecutor has died?\n",
      "Predicted Answer:  The type of action referenced by Scalia when the prosecutor has died is a civil action for malicious prosecution.\n",
      "Actual Answer: habeas action\n",
      "F1 Score: 0.0909\n",
      "\n",
      "Retrieved Sentence(s):\n",
      "page_content='the plaintiff.'\n",
      "page_content=\"I think it suggests how vital it is to rely on the trial court judge to make some credibility determination. He's there and sees the district attorney and tries to, after making appropriate\"\n",
      "page_content='although I am sure that the Court, in deliberations, will be considering the several jurisdictional issues which were briefed and argued earlier in the term. And if there are no questions on those'\n",
      "page_content=\"secondary consideration. So that in a case like Goodyear against Rayovac there's an excellent case where the claimed subject matter seems so simple in hindsight. This was a case decided by this Court\"\n",
      "\n",
      "Question: Why will the process be legthier?\n",
      "Predicted Answer:  The process will be easier because it will be divided into two separate approval processes for legal and para-legal personnel, giving them more time to complete the process before a reference entity is used.\n",
      "Actual Answer: the legal due-diligence\n",
      "F1 Score: 0.1026\n",
      "\n",
      "Retrieved Sentence(s):\n",
      "page_content='be producing formalising the procedure (most likely by means of a checklist)\\nto assist the lawyer/paralegal charged with performing the legal approval\\nprocess.'\n",
      "page_content='will have more lead time and be able to complete the process for both sites\\nbefore a reference entity is used.Mark Taylor has confirmed that the approval processes are separate for legal.'\n",
      "page_content='It is possible, given the tight timing, that some \"finishing touches\" needed\\nto be put to this process after the launch of the website.  Also, Legal will'\n",
      "page_content='I would appreciate it if you could facilitate this document through the\\nrequired processes.  lelsie just needs to review the changes that London made'\n",
      "\n",
      "Question: who is the first speaker?\n",
      "Predicted Answer:  The first speaker in the given context is not provided.\n",
      "Actual Answer: MR. HURD\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Retrieved Sentence(s):\n",
      "page_content=\"positions, but that's what it said. But, Your Honor, respectfully, we now know, because they've all written Law Review articles, that the people that wrote the House report, because they've said it,\"\n",
      "page_content='the plaintiff.'\n",
      "page_content='that supervisors in the executive branch be able to control and direct the work of their subordinates. The first amendment, which was adopted just a few years after the Constitution, was not meant to'\n",
      "page_content=\"article.Well, Your Honor, respectfully, what we do have is undisputed fact here because if you see Judge Weis' conclusion, for example, Judge Weis is one of the people who has adopted one of the\"\n",
      "\n",
      "Question: Which country has the new plane stuck?\n",
      "Predicted Answer:  The new plane is stuck in Iran.\n",
      "Actual Answer: Iran.\n",
      "F1 Score: 0.4000\n",
      "\n",
      "Retrieved Sentence(s):\n",
      "page_content=\"don't have any control over what might happen to that plane if it will get confiscated or seized by the government.Which would mean that Iran would get a brand-new fancy plane, which the sanctions\"\n",
      "page_content=\"plea in terms of foreign policy or national security interests, something a little more like, dear OFAC, if you don't grant us this exemption, this plane will stay in Iran. And if that happens...You\"\n",
      "page_content=\"passengers did get out. About a day later, a new plane flew into Shiraz just to get them. But as we sit here today, Norwegian Air's plane is still in Iran. For NPR News, I'm Karen Duffin.\"\n",
      "page_content='Norwegian Air did decline to go into detail with us when we called them, but we are guessing that they have already looked around in other countries. So they may just have to straight up beg for an'\n",
      "\n",
      "Question: Which names have Julia been experimenting more with capitalizing?\n",
      "Predicted Answer:  It's unclear from the given context which names Captain Obvious has experimented with capitalizing.\n",
      "Actual Answer: struct names\n",
      "F1 Score: 0.1111\n",
      "\n",
      "Retrieved Sentence(s):\n",
      "page_content=\"(I'm typing this as captain-obvious postmortem notes for my own benefit.)This reminds me, lately I've been experimenting more with capitalizing struct names.\"\n",
      "page_content=\"That might have helped here. But I'm not sure that's a good argument for or against capitalizing struct names.I guess it's really just, Racket lets you redefine _everything_. Which is awesome and\"\n",
      "page_content=\"With regard to the Relationship Terms, this is the first I've ever seen of\\nthis document and I'm not sure if I'm the appropriate person to review the\"\n",
      "page_content='language.Morally, readers just produce _s-expressions_, though they end up getting wrapped in syntax objects just so that they can have source locations attached. The produced s-expression is then'\n",
      "\n",
      "Question: What is the name of the casting director for the film Wendy Raquel Robinsondo worked on?\n",
      "Predicted Answer:  The casting director for the film Wendy Raquel Robinson worked on is not provided in the given context.\n",
      "Actual Answer: Robi Reed\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Retrieved Sentence(s):\n",
      "page_content='the plaintiff.'\n",
      "page_content=\"after the California Court of Appeal, a Federal magistrate, and a Federal district judge have agreed with the trial judge's perspectives. But it could be that she is quoting, as you'll see in the\"\n",
      "page_content='I believe I read this when it was featured (actually think it got featured because a girl built a CMS for her company in one day and someone commented this link on that page). I will re-read it again,'\n",
      "page_content=\"associate at the National Center for Children and Poverty, joined us from her office in New York City. Still with us here in the Studio 3A is Katherine Marshall Woods, who's a clinical psychologist\"\n",
      "\n",
      "Question: Which person is Neal hosting on the show?\n",
      "Predicted Answer:  Neal is hosting Geoffrey Bennett on the show.\n",
      "Actual Answer: Naomi Oreskes\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Retrieved Sentence(s):\n",
      "page_content=\"just an issue performance in business politics. One reader, Tambae Obenson(ph), he cut it down the middle.I wonder what the presence of Parsons and O'Neal really meant to their individual companies.\"\n",
      "page_content='Haedicke, who is at a management conference through the end of the week.\\n(Are we providing the bulk of the information to them or vice versa?)'\n",
      "page_content=\"Geoffrey Bennett.Hey, Geoff.Hello, Farai.So I understand that the future of black CEOs has become a hot topic. Last week, Stan O'Neal stepped down from Merrill Lynch, and this week, Time Warner\"\n",
      "page_content=\"associate at the National Center for Children and Poverty, joined us from her office in New York City. Still with us here in the Studio 3A is Katherine Marshall Woods, who's a clinical psychologist\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in answers_pairs:\n",
    "    f1_score = compute_f1(i[0][0],i[1]['result'])\n",
    "    print(f\"Question: {i[1]['query']}\")\n",
    "    print(f\"Predicted Answer: {i[1]['result']}\")\n",
    "    print(f\"Actual Answer: {i[0][0]}\")\n",
    "    print(f\"F1 Score: {f1_score:.4f}\")\n",
    "    retrieved_sentences = i[1].get('source_documents', [])\n",
    "    print(\"\\nRetrieved Sentence(s):\")\n",
    "    for sentence in retrieved_sentences:\n",
    "        print(sentence)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55d165b0",
   "metadata": {},
   "source": [
    "### 4.2 Retrieved Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4091b76b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1962d15a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from nltk.tokenize import sent_tokenize\n",
    "answers_pairs=[]\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=200, chunk_overlap=0.1)\n",
    "model_name = \"sentence-transformers/multi-qa-MiniLM-L6-cos-v1\"\n",
    "model_kwargs = {'device': 'cpu'}\n",
    "encode_kwargs = {'normalize_embeddings': True}\n",
    "\n",
    "def process_story_questions(combined_data, model_name, instruction):\n",
    "    hf_story_embs = HuggingFaceInstructEmbeddings(\n",
    "        model_name=model_name,\n",
    "        model_kwargs=model_kwargs,\n",
    "        encode_kwargs=encode_kwargs,\n",
    "        embed_instruction=\"Use the following pieces of context to answer the question at the end:\"\n",
    "    )\n",
    "\n",
    "    for cov in combined_data:\n",
    "        sentences = sent_tokenize(cov['text'])\n",
    "        sentence_embs = hf_story_embs.embed_documents(sentences)\n",
    "        #all_splits = text_splitter.split_text(cov['text'])\n",
    "        #vectorstore = Chroma.from_texts(texts=all_splits, embedding=word_embed)\n",
    "        #qa_chain = RetrievalQA.from_chain_type(llm, retriever=vectorstore.as_retriever(), return_source_documents=True)\n",
    "\n",
    "        question = cov['question'] \n",
    "        hf_query_embs = HuggingFaceInstructEmbeddings(\n",
    "            model_name=model_name,\n",
    "            model_kwargs=instruct_embedding_model_kwargs,\n",
    "            encode_kwargs=instruct_embedding_encode_kwargs,\n",
    "            query_instruction=instruction\n",
    "        )\n",
    "        question_emb = hf_query_embs.embed_query(question)\n",
    "        scores = [torch.cosine_similarity(torch.tensor(sentence_emb).unsqueeze(0), torch.tensor(question_emb).unsqueeze(0))[0].item() for sentence_emb in sentence_embs]\n",
    "        \n",
    "        best_sentence_idx = scores.index(max(scores))\n",
    "        best_sentence = sentences[best_sentence_idx]\n",
    "        \n",
    "        \n",
    "        #docs = vectorstore.similarity_search_by_vector(question_emb)\n",
    "        #predict = qa_chain({\"query\": question})\n",
    "        answers_pairs.append((cov['question'],cov['answers'],best_sentence))\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "325bb0f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load INSTRUCTOR_Transformer\n",
      "max_seq_length  512\n",
      "load INSTRUCTOR_Transformer\n",
      "max_seq_length  512\n",
      "load INSTRUCTOR_Transformer\n",
      "max_seq_length  512\n",
      "load INSTRUCTOR_Transformer\n",
      "max_seq_length  512\n",
      "load INSTRUCTOR_Transformer\n",
      "max_seq_length  512\n",
      "load INSTRUCTOR_Transformer\n",
      "max_seq_length  512\n",
      "load INSTRUCTOR_Transformer\n",
      "max_seq_length  512\n",
      "load INSTRUCTOR_Transformer\n",
      "max_seq_length  512\n",
      "load INSTRUCTOR_Transformer\n",
      "max_seq_length  512\n",
      "load INSTRUCTOR_Transformer\n",
      "max_seq_length  512\n",
      "load INSTRUCTOR_Transformer\n",
      "max_seq_length  512\n",
      "load INSTRUCTOR_Transformer\n",
      "max_seq_length  512\n",
      "load INSTRUCTOR_Transformer\n",
      "max_seq_length  512\n",
      "load INSTRUCTOR_Transformer\n",
      "max_seq_length  512\n",
      "load INSTRUCTOR_Transformer\n",
      "max_seq_length  512\n",
      "load INSTRUCTOR_Transformer\n",
      "max_seq_length  512\n",
      "load INSTRUCTOR_Transformer\n",
      "max_seq_length  512\n",
      "load INSTRUCTOR_Transformer\n",
      "max_seq_length  512\n",
      "load INSTRUCTOR_Transformer\n",
      "max_seq_length  512\n",
      "load INSTRUCTOR_Transformer\n",
      "max_seq_length  512\n",
      "load INSTRUCTOR_Transformer\n",
      "max_seq_length  512\n",
      "load INSTRUCTOR_Transformer\n",
      "max_seq_length  512\n",
      "load INSTRUCTOR_Transformer\n",
      "max_seq_length  512\n",
      "load INSTRUCTOR_Transformer\n",
      "max_seq_length  512\n",
      "load INSTRUCTOR_Transformer\n",
      "max_seq_length  512\n",
      "load INSTRUCTOR_Transformer\n",
      "max_seq_length  512\n",
      "load INSTRUCTOR_Transformer\n",
      "max_seq_length  512\n",
      "load INSTRUCTOR_Transformer\n",
      "max_seq_length  512\n",
      "load INSTRUCTOR_Transformer\n",
      "max_seq_length  512\n",
      "load INSTRUCTOR_Transformer\n",
      "max_seq_length  512\n",
      "load INSTRUCTOR_Transformer\n",
      "max_seq_length  512\n",
      "load INSTRUCTOR_Transformer\n",
      "max_seq_length  512\n",
      "load INSTRUCTOR_Transformer\n",
      "max_seq_length  512\n",
      "load INSTRUCTOR_Transformer\n",
      "max_seq_length  512\n",
      "load INSTRUCTOR_Transformer\n",
      "max_seq_length  512\n",
      "load INSTRUCTOR_Transformer\n",
      "max_seq_length  512\n",
      "load INSTRUCTOR_Transformer\n",
      "max_seq_length  512\n"
     ]
    }
   ],
   "source": [
    "model_name = \"sentence-transformers/multi-qa-MiniLM-L6-cos-v1\"\n",
    "instruction = \"Represent the story for retrieval:\" \n",
    "process_story_questions(combined_data, model_name, instruction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ea7da7bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Which program does Suellen reference that shares its name with a snake?\n",
      "Predicted Answer: But I'm sure it can make for quick test development&gt; dislike because of the magicnessyeah, I hate python, where is my `malloc()` ,stuck_out_tongue,Not really the same thingIn this case I'm talking about decorators that magically rewrite things to inject arguments^ that's my biggest concern, too.why magically?\n",
      "Actual Answer: ['Python']\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Question: Which person is talking to the Chief Justice?\n",
      "Predicted Answer: Chief Justice, and may it please the Court, Much of the work of public employees is performed by speaking or writing, and much of that work concerns matters of public interest.\n",
      "Actual Answer: ['Mr. Kneedler']\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Question: What is the name of the most important center of learning of Sunni Islam in the country where the pope is going to celebrate a mass tomorrow ?\n",
      "Predicted Answer: It's the most important center of learning of Sunni Islam.\n",
      "Actual Answer: ['Al-Azhar University']\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Question: Who hosts NEWS & NOTES?\n",
      "Predicted Answer: Here at NEWS & NOTES, we have our own 40 acres of the blogosphere, News & Views.\n",
      "Actual Answer: ['FARAI CHIDEYA']\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Question: Which feature in DrRacket inserts an epsilon?\n",
      "Predicted Answer: Using \\epsilon in DrRacket inserts an epsilon as expected.\n",
      "Actual Answer: ['\\\\epsilon']\n",
      "F1 Score: 0.1818\n",
      "\n",
      "Question: What is the name of the clinical psychologist with the Psychological Group of Washington?\n",
      "Predicted Answer: Still with us here in the Studio 3A is Katherine Marshall Woods, who's a clinical psychologist with the Psychological Group of Washington.\n",
      "Actual Answer: ['Katherine Marshall Woods']\n",
      "F1 Score: 0.2143\n",
      "\n",
      "Question: what was the name of the case?\n",
      "Predicted Answer: He would be deciding an issue that normally would be submitted to the jury.It's not our position, Your Honor, that -- that the trial court can make credibility determinations, but --But the example that Justice Kennedy gave you was such a determination.I -- I think, though -- I -- I suppose that would depend on the nature of the specific evidence at issue.\n",
      "Actual Answer: ['baby-shaking case']\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Question: Who is the Chief Justice of  United States ?\n",
      "Predicted Answer: This was a case decided by this Court in 1944.\n",
      "Actual Answer: ['CHIEF JUSTICE ROBERTS']\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Question: What proportion of African American jurors were struck?\n",
      "Predicted Answer: There we have 10 of 11 African American jurors struck.\n",
      "Actual Answer: ['10 of 11']\n",
      "F1 Score: 0.4286\n",
      "\n",
      "Question: Which NPR reporter was traveling in South Carolina?\n",
      "Predicted Answer: Don, I have to cut you off to go to a break, but I want to thank NPR's Don Gonyea traveling in South Carolina.\n",
      "Actual Answer: ['Don Gonyea']\n",
      "F1 Score: 0.1333\n",
      "\n",
      "Question: Who is the only person that needs Denis O'Connell to sign a bilateral NDA?\n",
      "Predicted Answer: As provided in my first set\n",
      "of comments, the maximum term that I have authority to approve is 2 years for\n",
      "a bilateral NDA.\n",
      "Actual Answer: ['Leslie.Hansen']\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Question: In which industry lynda need the survey about developers?\n",
      "Predicted Answer: Thanks for your help.Hi everyone, Iâ€™m a UX design student working on a developersâ€™ career advice project and I would really appreciate if you could take 1 minute and help me participate in this survey about developers in tech industry.\n",
      "Actual Answer: ['tech industry']\n",
      "F1 Score: 0.0851\n",
      "\n",
      "Question: What is the name of the petitioner in the case?\n",
      "Predicted Answer: It is then appealable either to a zoning board of adjustment -- that's the -- the model act -- or in California, States -- localities have the option of having the appeal go to the local legislature.\n",
      "Actual Answer: ['Mr. Lamken']\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Question: Which act has a piece missing from it, according to the Circuit court?\n",
      "Predicted Answer: And just to respond to something that was said about the Federal Whistle-blower Protection Act, that statute has a gaping hole in it, as construed by the Federal Circuit, because the Federal Circuit has construed it to exclude protection for speech that is part of the employee's normal duties.\n",
      "Actual Answer: ['Federal Whistle-blower Protection Act']\n",
      "F1 Score: 0.1379\n",
      "\n",
      "Question: Which restatement section was based on injured party?\n",
      "Predicted Answer: The restatement section, section three- -- or the restatement section 324 says reliance is from the other for the injured party.\n",
      "Actual Answer: ['Section 324']\n",
      "F1 Score: 0.0800\n",
      "\n",
      "Question: How many months of unpaid leave does anyone with a permanent position have in Sweden ?\n",
      "Predicted Answer: It's quite a risk to start all over, no income whatsoever at the beginning.Her story isn't unusual in Sweden, where anyone with a permanent position has a legal right to take unpaid leave for six months to launch a company, providing it doesn't compete with their usual employer.To find out more, I braved the snow and made a visit to Samuel Engblom at the Swedish Confederation for Professional Employees, which represents white-collar workers.\n",
      "Actual Answer: ['six']\n",
      "F1 Score: 0.0241\n",
      "\n",
      "Question: What is the name of the amendment that requires reliability in the determination that death is an appropriate sentence ?\n",
      "Predicted Answer: To pick up on some of the things that were said during Attorney General Kline's argument, the Eighth Amendment requires reliability in the determination that death is an appropriate sentence.\n",
      "Actual Answer: ['Eighth Amendment']\n",
      "F1 Score: 0.1143\n",
      "\n",
      "Question: Which month does Kate think the price of $292.50 possibly sounds right for?\n",
      "Predicted Answer: But he\n",
      "said a price like $292.50 doesn't sound right for Sept. - possibly May?This is what amerex is showing and this is what I have confirmed.This is what amerex is showing and this is what I have confirmed.Yep - the trade's there all right.\n",
      "Actual Answer: ['May']\n",
      "F1 Score: 0.0385\n",
      "\n",
      "Question: In which case Judge Weis gave his opinion ?\n",
      "Predicted Answer: But, Your Honor, respectfully, we now know, because they've all written Law Review articles, that the people that wrote the House report, because they've said it, wrote those law -- wrote those words because they knew that the language did overrule Zahn and they didn't want to achieve that outcome.I think -- I think you're overstating what they say in the article.Well, Your Honor, respectfully, what we do have is undisputed fact here because if you see Judge Weis' conclusion, for example, Judge Weis is one of the people who has adopted one of the opinions opposing our view of -- of this position.He was the chair of the --He was.\n",
      "Actual Answer: ['Meritcare v. St. Paul']\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Question: Which company is giving the official confirmation letter for not to use their representative name?\n",
      "Predicted Answer: Paul S. Rosica\n",
      "Lehman Brothers\n",
      "212-526-8887 Phone\n",
      "212-526-2755 Fax\n",
      "917-822-9797 Cell\n",
      "<email>\n",
      "\n",
      "This message is intended only for the personal and confidential use of the\n",
      "designated recipient(s) named above.\n",
      "Actual Answer: ['Lehman Brothers Inc']\n",
      "F1 Score: 0.1053\n",
      "\n",
      "Question: Jason Rezaian wrote stories for which paper?\n",
      "Predicted Answer: So the Iranian power structure is broken up into different parts.\n",
      "Actual Answer: ['the Washington Post']\n",
      "F1 Score: 0.1333\n",
      "\n",
      "Question: Where does Deeanna want to move 'blueprints' into?\n",
      "Predicted Answer: It doesn't work when I deploy the package because the location of `blueprints` is outside of the package's installation path so I get this error after I install the package,\n",
      "\n",
      " <code_snippet> \n",
      "\n",
      "If I move blueprints inside `koyo-lib`, then that causes problems as well because `blueprints` contains racket code (and koyo-lib is declared as a multi-collection package (though I could change it to a single collection package, but I'm not sure that would help)).So what I would like to do is move `blueprints` into `koyo-lib` but somehow tell `raco pkg` that it should ignore the `blueprints` folder when `koyo-lib` is installed.I have read about the `source-omit-files` configuration value but I don't think that'll do what I want.\n",
      "Actual Answer: ['`koyo-lib`']\n",
      "F1 Score: 0.0392\n",
      "\n",
      "Question: What time is the OU-Enron game ?\n",
      "Predicted Answer: We play the other Enron team.\n",
      "Actual Answer: ['700']\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Question: What type of spy would have rights under regulations for handling secret contracts , Justice Clemmler says ?\n",
      "Predicted Answer: Alleged spies would have rights under those regulations, and the very idea of walking into court and asserting your rights as an alleged spy is inconsistent with the entire relationship and the contract that gave rise to it.\n",
      "Actual Answer: ['were a party to a secret contract or at least a secret relationship']\n",
      "F1 Score: 0.1132\n",
      "\n",
      "Question: Which types of networks are involved?\n",
      "Predicted Answer: There are some other things, too, involving a spreading-activation network and a network by which nodes support the continued existence of other nodes.So, tagswhatâ€™s a `tag?` value?Each node has a bunch of attributes, just an arbitrary hash table.\n",
      "Actual Answer: ['a spreading-activation network and a network by which nodes support the continued existence of other nodes']\n",
      "F1 Score: 0.4545\n",
      "\n",
      "Question: Transactions will be between which two entities?\n",
      "Predicted Answer: Transactions will be between company offering product and customer; Enron does not stand in middle for credit.\n",
      "Actual Answer: ['company offering product and customer']\n",
      "F1 Score: 0.4167\n",
      "\n",
      "Question: What program allows the user to parallelize the tests and is recommended by Karoline?\n",
      "Predicted Answer: basically they allow you to paralelize your testsOkayWill definitely look into thoseThanks <@Eliana> <@Karoline> ,taco,Having a simple issue.\n",
      "Actual Answer: ['pytest-parallel']\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Question: What does the Court say imposes restrictions on the discretion of police?\n",
      "Predicted Answer: And we believe the Fourth Amendment does impose -- the Fourth Amendment itself imposes restrictions on the discretion of police officers and parole officers that are meaningful, that -- as the Reyes Court said, there are restrictions on the timing, the frequency, the duration, and the oppressiveness of the search.\n",
      "Actual Answer: ['restrictions on the timing, the frequency, the duration, and the oppressiveness of the search']\n",
      "F1 Score: 0.4658\n",
      "\n",
      "Question: Who is restrained in the circumstances of the trial?\n",
      "Predicted Answer: Again, it -- it depends upon the circumstances, but if they're not visible to the jury, the defendant has a difficult time --Well, the circumstances that you were given was a traffic offender.A traffic offender who is restrained where it's not visible --With -- with non-visible restraints.\n",
      "Actual Answer: ['Mr. Deck']\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Question: What kind of action is referenced by Scalia when the prosecutor has died?\n",
      "Predicted Answer: The prosecutor is dead.That's about four questions, Your Honor.\n",
      "Actual Answer: ['habeas action']\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Question: Why will the process be legthier?\n",
      "Predicted Answer: That process is now underway.\n",
      "Actual Answer: ['the legal due-diligence']\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Question: who is the first speaker?\n",
      "Predicted Answer: I'm worried, however, about the fact that this statute doesn't just cover the initial IEP.\n",
      "Actual Answer: ['MR. HURD']\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Question: Which country has the new plane stuck?\n",
      "Predicted Answer: But as we sit here today, Norwegian Air's plane is still in Iran.\n",
      "Actual Answer: ['Iran.']\n",
      "F1 Score: 0.2222\n",
      "\n",
      "Question: Which names have Julia been experimenting more with capitalizing?\n",
      "Predicted Answer: )This reminds me, lately I've been experimenting more with capitalizing struct names.\n",
      "Actual Answer: ['struct names']\n",
      "F1 Score: 0.2222\n",
      "\n",
      "Question: What is the name of the casting director for the film Wendy Raquel Robinsondo worked on?\n",
      "Predicted Answer: I knew Robi Reed who was also the casting director, and (unintelligible) who was actually working on it.\n",
      "Actual Answer: ['Robi Reed']\n",
      "F1 Score: 0.1667\n",
      "\n",
      "Question: Which person is Neal hosting on the show?\n",
      "Predicted Answer: I'm Neal Conan in Washington.\n",
      "Actual Answer: ['Naomi Oreskes']\n",
      "F1 Score: 0.0000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in answers_pairs:\n",
    "    f1_score = compute_f1(i[1][0],i[2])\n",
    "    print(f\"Question: {i[0]}\")\n",
    "    print(f\"Predicted Answer: {i[2]}\")\n",
    "    print(f\"Actual Answer: {i[1]}\")\n",
    "    print(f\"F1 Score: {f1_score:.4f}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ba914059",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Python']\n",
      "['Mr. Kneedler']\n",
      "['Al-Azhar University']\n",
      "['FARAI CHIDEYA']\n",
      "['\\\\epsilon']\n",
      "['Katherine Marshall Woods']\n",
      "['baby-shaking case']\n",
      "['CHIEF JUSTICE ROBERTS']\n",
      "['10 of 11']\n",
      "['Don Gonyea']\n",
      "['Leslie.Hansen']\n",
      "['tech industry']\n",
      "['Mr. Lamken']\n",
      "['Federal Whistle-blower Protection Act']\n",
      "['Section 324']\n",
      "['six']\n",
      "['Eighth Amendment']\n",
      "['May']\n",
      "['Meritcare v. St. Paul']\n",
      "['Lehman Brothers Inc']\n",
      "['the Washington Post']\n",
      "['`koyo-lib`']\n",
      "['700']\n",
      "['were a party to a secret contract or at least a secret relationship']\n",
      "['a spreading-activation network and a network by which nodes support the continued existence of other nodes']\n",
      "['company offering product and customer']\n",
      "['pytest-parallel']\n",
      "['restrictions on the timing, the frequency, the duration, and the oppressiveness of the search']\n",
      "['Mr. Deck']\n",
      "['habeas action']\n",
      "['the legal due-diligence']\n",
      "['MR. HURD']\n",
      "['Iran.']\n",
      "['struct names']\n",
      "['Robi Reed']\n",
      "['Naomi Oreskes']\n"
     ]
    }
   ],
   "source": [
    "for i in answers_pairs:\n",
    "    f1_score = compute_f1(i[0][0],i[1])\n",
    "    print(f\"Question: {i[1]['query']}\")\n",
    "    print(f\"Predicted Answer: {i[1]['result']}\")\n",
    "    print(f\"Actual Answer: {i[0][0]}\")\n",
    "    print(f\"F1 Score: {f1_score:.4f}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18200dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "def process_story_questions(data, model_name, instruction):\n",
    "    model_kwargs = {'device': 'cpu'}\n",
    "    encode_kwargs = {'normalize_embeddings': True}\n",
    "\n",
    "    # Segment story text into sentences and embed each sentence\n",
    "    sentences = sent_tokenize(story_text)  # Splitting into sentences\n",
    "    hf_story_embs = HuggingFaceInstructEmbeddings(\n",
    "        model_name=model_name,\n",
    "        model_kwargs=model_kwargs,\n",
    "        encode_kwargs=encode_kwargs,\n",
    "        embed_instruction=\"Use the following pieces of context to answer the question at the end:\"\n",
    "    )\n",
    "    sentence_embs = hf_story_embs.embed_documents(sentences)\n",
    "\n",
    "    # Process each question\n",
    "    for question_data in story_data['questions']:\n",
    "        question = question_data['q']\n",
    "\n",
    "        hf_query_embs = HuggingFaceInstructEmbeddings(\n",
    "            model_name=model_name,\n",
    "            model_kwargs=model_kwargs,\n",
    "            encode_kwargs=encode_kwargs,\n",
    "            query_instruction=instruction\n",
    "        )\n",
    "        question_emb = hf_query_embs.embed_documents([question])[0]\n",
    "\n",
    "        # Compute cosine similarity scores with each sentence\n",
    "        scores = [torch.cosine_similarity(torch.tensor(sentence_emb).unsqueeze(0), torch.tensor(question_emb).unsqueeze(0))[0].item() for sentence_emb in sentence_embs]\n",
    "\n",
    "        best_sentence_idx = scores.index(max(scores))\n",
    "        best_sentence = sentences[best_sentence_idx]\n",
    "\n",
    "        # Extract actual answer using the consensus range\n",
    "        consensus = question_data['consensus']\n",
    "        actual_answer = story_text[consensus['s']:consensus['e']]\n",
    "        \n",
    "        # Calculate F1 score\n",
    "        f1_score = compute_f1(best_sentence, actual_answer)\n",
    "        \n",
    "        # Print results\n",
    "        print(f\"Question: {question}\")\n",
    "        print(f\"Predicted Answer: {best_sentence}\")\n",
    "        print(f\"Actual Answer: {actual_answer}\")\n",
    "        print(f\"F1 Score: {f1_score:.4f}\")\n",
    "        print()\n",
    "        \n",
    "        \n",
    "        # # Calculate F1 score for each sentence\n",
    "        # f1_scores = [compute_f1(sentence, question) for sentence in sentences]\n",
    "\n",
    "        # # Find the sentence with the highest F1 score\n",
    "        # best_sentence_idx = f1_scores.index(max(f1_scores))\n",
    "        # best_sentence = sentences[best_sentence_idx]\n",
    "\n",
    "        # # Extract actual answer using the consensus range\n",
    "        # consensus = question_data['consensus']\n",
    "        # actual_answer = story_text[consensus['s']:consensus['e']]\n",
    "        \n",
    "        # # Calculate F1 score\n",
    "        # f1_score = compute_f1(best_sentence, actual_answer)\n",
    "        \n",
    "        # # Print results\n",
    "        # print(f\"Question: {question}\")\n",
    "        # print(f\"Predicted Answer: {best_sentence}\")\n",
    "        # print(f\"Actual Answer: {actual_answer}\")\n",
    "        # print(f\"F1 Score: {f1_score:.4f}\")\n",
    "        # print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a914da",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"sentence-transformers/multi-qa-MiniLM-L6-cos-v1\"\n",
    "instruction = \"Represent the story for retrieval:\" \n",
    "process_story_questions(combined_data, model_name, instruction)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
